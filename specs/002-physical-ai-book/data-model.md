# Data Model: Physical AI & Humanoid Robotics Textbook

**Date**: 2025-11-27
**Feature**: 002-physical-ai-book
**Purpose**: Database schema, entity relationships, and data validation rules

---

## Database Technology

**Primary Database**: Neon Serverless Postgres (Free Tier)
- **Connection**: `postgresql://user:password@host.region.neon.tech/dbname?sslmode=require`
- **Driver**: psycopg2-binary 2.9+
- **Features Used**: SERIAL primary keys, JSONB columns, foreign keys, indexes, CHECK constraints

**Vector Database**: Qdrant Cloud Free Tier (reused from 001-hackathon-app)
- **Purpose**: Store textbook content embeddings for RAG queries
- **Schema**: See 001-hackathon-app data-model.md for Text Chunk structure

---

## Entity-Relationship Diagram

```
┌─────────────────────────┐
│        users            │
├─────────────────────────┤
│ id (PK)                 │
│ email (UNIQUE)          │
│ password_hash           │
│ software_background     │ (JSONB)
│ hardware_background     │ (JSONB)
│ created_at              │
│ last_login              │
└──────────┬──────────────┘
           │
           │ 1:N (nullable)
           │
           ▼
┌─────────────────────────┐
│    conversations        │
├─────────────────────────┤
│ id (PK)                 │
│ user_id (FK, NULL OK)   │
│ session_id              │
│ question                │
│ answer                  │
│ citations               │ (JSONB)
│ question_type           │
│ timestamp               │
└─────────────────────────┘
```

**Relationship Notes**:
- **users → conversations**: One-to-many, but user_id is nullable (allows anonymous conversations with session_id)
- **ON DELETE SET NULL**: If user is deleted, conversations are preserved with user_id = NULL
- **Session tracking**: Anonymous users identified by session_id (UUID generated by frontend)

---

## Table Schemas

### 1. Users Table

**Purpose**: Store user accounts with authentication credentials and background information

```sql
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    software_background JSONB,
    hardware_background JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    last_login TIMESTAMP
);

-- Indexes
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_created_at ON users(created_at DESC);
```

**Column Definitions**:

| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| `id` | SERIAL | PRIMARY KEY | Auto-incrementing user ID |
| `email` | VARCHAR(255) | UNIQUE NOT NULL | User's email address (login identifier) |
| `password_hash` | VARCHAR(255) | NOT NULL | Bcrypt-hashed password (60 characters for bcrypt, padded to 255 for future algorithms) |
| `software_background` | JSONB | NULL OK | JSON object with programming languages, robotics experience, AI/ML level |
| `hardware_background` | JSONB | NULL OK | JSON object with RTX GPU access, Jetson kit, robot hardware |
| `created_at` | TIMESTAMP | DEFAULT NOW() | Account creation timestamp |
| `last_login` | TIMESTAMP | NULL OK | Last successful signin timestamp |

**JSONB Schema** (software_background):
```json
{
  "programming_languages": ["Python", "C++", "JavaScript"],
  "robotics_experience": "intermediate",  // "none" | "beginner" | "intermediate" | "advanced"
  "ai_ml_level": "advanced",  // "none" | "basic" | "intermediate" | "advanced"
  "prior_courses": ["CS101", "Robotics 101"]  // Optional array
}
```

**JSONB Schema** (hardware_background):
```json
{
  "rtx_gpu_access": true,  // boolean
  "rtx_gpu_model": "RTX 4070 Ti",  // string, optional
  "jetson_kit": "Orin Nano 8GB",  // "none" | "Orin Nano 8GB" | "Orin NX 16GB" | other
  "robot_hardware": "none"  // "none" | "quadruped" | "humanoid" | "robotic_arm" | other
}
```

**Validation Rules** (enforced at application level in FastAPI):
- Email must match regex pattern: `^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$`
- Password must be at least 8 characters before hashing
- software_background fields: robotics_experience and ai_ml_level must be in predefined enums
- hardware_background fields: rtx_gpu_access must be boolean

---

### 2. Conversations Table

**Purpose**: Store all chatbot interactions (RAG and selected-text mode) with user attribution and source citations

```sql
CREATE TABLE conversations (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id) ON DELETE SET NULL,
    session_id VARCHAR(255),
    question TEXT NOT NULL,
    answer TEXT NOT NULL,
    citations JSONB,
    question_type VARCHAR(50) CHECK (question_type IN ('rag', 'selected_text')),
    timestamp TIMESTAMP DEFAULT NOW()
);

-- Indexes
CREATE INDEX idx_conversations_user_id ON conversations(user_id);
CREATE INDEX idx_conversations_session_id ON conversations(session_id);
CREATE INDEX idx_conversations_timestamp ON conversations(timestamp DESC);
CREATE INDEX idx_conversations_question_type ON conversations(question_type);
```

**Column Definitions**:

| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| `id` | SERIAL | PRIMARY KEY | Auto-incrementing conversation ID |
| `user_id` | INTEGER | FOREIGN KEY, NULL OK | References users(id), NULL for anonymous conversations |
| `session_id` | VARCHAR(255) | NULL OK | UUID for anonymous user tracking (frontend-generated) |
| `question` | TEXT | NOT NULL | Student's question text |
| `answer` | TEXT | NOT NULL | Chatbot's generated answer |
| `citations` | JSONB | NULL OK | Array of source citations with module, chapter, chunk_id, relevance_score |
| `question_type` | VARCHAR(50) | CHECK constraint | 'rag' (vector search) or 'selected_text' (context-only) |
| `timestamp` | TIMESTAMP | DEFAULT NOW() | When conversation occurred |

**JSONB Schema** (citations):
```json
[
  {
    "module": "Module 1: ROS 2",
    "chapter": "Nodes and Topics",
    "chunk_id": "chunk_42",
    "relevance_score": 0.89
  },
  {
    "module": "Module 3: NVIDIA Isaac",
    "chapter": "Isaac ROS",
    "chunk_id": "chunk_156",
    "relevance_score": 0.75
  }
]
```

**Validation Rules**:
- `question` and `answer` must not be empty strings
- `user_id` OR `session_id` must be present (at least one non-null)
- `question_type` must be exactly 'rag' or 'selected_text' (enforced by CHECK constraint)
- `citations` must be a valid JSON array (if present)

**Query Patterns**:

```sql
-- Get all conversations for a logged-in user
SELECT * FROM conversations WHERE user_id = $1 ORDER BY timestamp DESC;

-- Get all conversations for an anonymous session
SELECT * FROM conversations WHERE session_id = $1 ORDER BY timestamp DESC;

-- Get recent RAG conversations
SELECT * FROM conversations WHERE question_type = 'rag' ORDER BY timestamp DESC LIMIT 10;

-- Find conversations citing a specific module
SELECT * FROM conversations WHERE citations @> '[{"module": "Module 1: ROS 2"}]';
```

---

## Entity Definitions (Application Layer)

### 3. User (Pydantic Model)

**Purpose**: Application-level representation of users table

```python
from pydantic import BaseModel, EmailStr
from typing import Optional, List
from datetime import datetime

class SoftwareBackground(BaseModel):
    programming_languages: List[str]
    robotics_experience: str  # "none" | "beginner" | "intermediate" | "advanced"
    ai_ml_level: str  # "none" | "basic" | "intermediate" | "advanced"
    prior_courses: Optional[List[str]] = []

class HardwareBackground(BaseModel):
    rtx_gpu_access: bool
    rtx_gpu_model: Optional[str] = None
    jetson_kit: str  # "none" | "Orin Nano 8GB" | "Orin NX 16GB" | other
    robot_hardware: str  # "none" | "quadruped" | "humanoid" | "robotic_arm" | other

class User(BaseModel):
    id: int
    email: EmailStr
    software_background: Optional[SoftwareBackground] = None
    hardware_background: Optional[HardwareBackground] = None
    created_at: datetime
    last_login: Optional[datetime] = None

class UserCreate(BaseModel):
    email: EmailStr
    password: str  # Plain password (will be hashed)
    software_background: SoftwareBackground
    hardware_background: HardwareBackground

class UserLogin(BaseModel):
    email: EmailStr
    password: str
```

---

### 4. Conversation (Pydantic Model)

**Purpose**: Application-level representation of conversations table

```python
from pydantic import BaseModel
from typing import Optional, List
from datetime import datetime

class Citation(BaseModel):
    module: str
    chapter: str
    chunk_id: str
    relevance_score: float

class Conversation(BaseModel):
    id: int
    user_id: Optional[int] = None
    session_id: Optional[str] = None
    question: str
    answer: str
    citations: List[Citation] = []
    question_type: str  # "rag" | "selected_text"
    timestamp: datetime

class ConversationCreate(BaseModel):
    user_id: Optional[int] = None
    session_id: Optional[str] = None
    question: str
    answer: str
    citations: List[Citation] = []
    question_type: str  # "rag" | "selected_text"
```

---

### 5. Module & Chapter (Content Organization, No Database)

**Purpose**: Logical organization of textbook content (Docusaurus markdown files)

**Module Structure**:
- Module 1: ROS 2 - The Robotic Nervous System (Weeks 3-5)
  - Chapters: ros2-architecture, nodes-topics-services, python-integration, urdf-for-humanoids
- Module 2: Gazebo & Unity - The Digital Twin (Weeks 6-7)
  - Chapters: gazebo-simulation, urdf-sdf-formats, physics-simulation, unity-rendering
- Module 3: NVIDIA Isaac - The AI-Robot Brain (Weeks 8-10)
  - Chapters: isaac-sim, isaac-ros, vslam-navigation, nav2-planning
- Module 4: Vision-Language-Action (Week 13)
  - Chapters: voice-to-action, cognitive-planning, capstone-project

**Chapter Metadata** (stored in markdown frontmatter):
```yaml
---
id: nodes-topics-services
title: "Nodes, Topics, and Services"
sidebar_label: "Nodes & Topics"
module: "Module 1: ROS 2"
week: 3
learning_objectives:
  - "Understand ROS 2 node architecture"
  - "Implement publish/subscribe communication"
  - "Create service clients and servers"
---
```

---

### 6. Text Chunk (Qdrant Vector, Reused from 001-hackathon-app)

**Purpose**: Represent textbook content chunks stored in Qdrant for RAG

```python
from pydantic import BaseModel
from typing import List, Dict, Optional

class TextChunk(BaseModel):
    chunk_id: str  # UUID
    text: str  # Chunk content (200-300 tokens)
    embedding: List[float]  # 1536-dim vector from OpenAI text-embedding-3-small
    module: str  # "Module 1: ROS 2"
    chapter: str  # "Nodes and Topics"
    chunk_index: int  # Position within chapter (0, 1, 2, ...)
    token_count: int  # Actual token count (using tiktoken)
    metadata: Optional[Dict] = {}  # Additional context (page, section, etc.)
```

**Qdrant Collection Schema**:
- Collection name: `physical_ai_textbook`
- Vector size: 1536 (OpenAI text-embedding-3-small)
- Distance metric: Cosine similarity
- Payload: {module, chapter, chunk_index, token_count, text}

---

## Data Validation Rules

### User Data Validation

**Email**:
- Required, must be unique
- Regex: `^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$`
- Example valid: `student@university.edu`
- Example invalid: `student@`, `@university.edu`, `student university.edu`

**Password**:
- Minimum 8 characters
- Recommended: At least one uppercase, one lowercase, one digit (not enforced at database level)
- Hashed with bcrypt before storage (never stored as plain text)

**Software Background**:
- `robotics_experience`: Must be one of `["none", "beginner", "intermediate", "advanced"]`
- `ai_ml_level`: Must be one of `["none", "basic", "intermediate", "advanced"]`
- `programming_languages`: Array of strings, at least one element recommended

**Hardware Background**:
- `rtx_gpu_access`: Boolean (true/false)
- `jetson_kit`: String, any value allowed (flexibility for new hardware)
- `robot_hardware`: String, any value allowed

---

### Conversation Data Validation

**Question**:
- Required, minimum 3 characters
- Maximum 2,000 characters (reasonable limit for questions)

**Answer**:
- Required, minimum 10 characters
- No maximum (generated answers can be long)

**Question Type**:
- Must be exactly `"rag"` or `"selected_text"`
- Enforced by database CHECK constraint

**User/Session Attribution**:
- At least one of `user_id` or `session_id` must be present
- `user_id` takes precedence if both provided (logged-in user)

**Citations**:
- Must be valid JSON array if present
- Each citation must have: `module` (string), `chapter` (string), `chunk_id` (string), `relevance_score` (float 0.0-1.0)

---

## Migration Scripts

### Initial Schema Migration (001_initial.sql)

```sql
-- Create users table
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    software_background JSONB,
    hardware_background JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    last_login TIMESTAMP
);

-- Create indexes on users
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_created_at ON users(created_at DESC);

-- Create conversations table
CREATE TABLE conversations (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id) ON DELETE SET NULL,
    session_id VARCHAR(255),
    question TEXT NOT NULL,
    answer TEXT NOT NULL,
    citations JSONB,
    question_type VARCHAR(50) CHECK (question_type IN ('rag', 'selected_text')),
    timestamp TIMESTAMP DEFAULT NOW()
);

-- Create indexes on conversations
CREATE INDEX idx_conversations_user_id ON conversations(user_id);
CREATE INDEX idx_conversations_session_id ON conversations(session_id);
CREATE INDEX idx_conversations_timestamp ON conversations(timestamp DESC);
CREATE INDEX idx_conversations_question_type ON conversations(question_type);

-- Verify schema
SELECT table_name, column_name, data_type
FROM information_schema.columns
WHERE table_schema = 'public'
ORDER BY table_name, ordinal_position;
```

**To Apply Migration**:
1. Connect to Neon Postgres: `psql <NEON_DATABASE_URL>`
2. Run migration: `\i backend/src/db/migrations/001_initial.sql`
3. Verify: `\dt` (list tables), `\d users` (describe users table)

### Translation Cache Migration (002_translations.sql)

**Purpose**: Store translated content to avoid re-translating same chapters and reduce API costs

```sql
-- Create translations table
CREATE TABLE translations (
    id SERIAL PRIMARY KEY,
    chapter_id VARCHAR(255) NOT NULL,
    language VARCHAR(10) NOT NULL DEFAULT 'urdu',
    translated_content TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Create indexes on translations
CREATE INDEX idx_translations_chapter_language ON translations(chapter_id, language);
CREATE INDEX idx_translations_created_at ON translations(created_at DESC);

-- Verify schema
SELECT table_name, column_name, data_type
FROM information_schema.columns
WHERE table_schema = 'public' AND table_name = 'translations'
ORDER BY ordinal_position;
```

**Column Definitions**:

| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| `id` | SERIAL | PRIMARY KEY | Auto-incrementing translation ID |
| `chapter_id` | VARCHAR(255) | NOT NULL | Chapter identifier (e.g., "module1-ros2-architecture") |
| `language` | VARCHAR(10) | NOT NULL, DEFAULT 'urdu' | Target language code (currently 'urdu', extensible for future languages) |
| `translated_content` | TEXT | NOT NULL | Full translated chapter content in target language |
| `created_at` | TIMESTAMP | DEFAULT NOW() | When translation was cached |

**Query Patterns**:

```sql
-- Check if translation exists for a chapter
SELECT translated_content FROM translations 
WHERE chapter_id = $1 AND language = 'urdu';

-- Store new translation
INSERT INTO translations (chapter_id, language, translated_content)
VALUES ($1, 'urdu', $2)
RETURNING id, created_at;
```

**To Apply Migration**:
1. Connect to Neon Postgres: `psql <NEON_DATABASE_URL>`
2. Run migration: `\i backend/src/db/migrations/002_translations.sql`
3. Verify: `\d translations` (describe translations table)

---

## Database Access Patterns

### Connection Pool Management

```python
import psycopg2
from psycopg2 import pool
import os

# Initialize at app startup (FastAPI lifespan event)
def init_db_pool():
    global connection_pool
    connection_pool = psycopg2.pool.SimpleConnectionPool(
        minconn=1,
        maxconn=10,
        dsn=os.getenv("NEON_DATABASE_URL")
    )

# Get connection from pool
def get_db_connection():
    return connection_pool.getconn()

# Return connection to pool
def release_db_connection(conn):
    connection_pool.putconn(conn)
```

### Example Queries

**Create User**:
```python
def create_user(email, password_hash, software_bg, hardware_bg):
    conn = get_db_connection()
    try:
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO users (email, password_hash, software_background, hardware_background)
            VALUES (%s, %s, %s, %s)
            RETURNING id, email, created_at
            """,
            (email, password_hash, json.dumps(software_bg), json.dumps(hardware_bg))
        )
        result = cursor.fetchone()
        conn.commit()
        return {"id": result[0], "email": result[1], "created_at": result[2]}
    finally:
        cursor.close()
        release_db_connection(conn)
```

**Save Conversation**:
```python
def save_conversation(user_id, session_id, question, answer, citations, question_type):
    conn = get_db_connection()
    try:
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO conversations
            (user_id, session_id, question, answer, citations, question_type)
            VALUES (%s, %s, %s, %s, %s, %s)
            RETURNING id, timestamp
            """,
            (user_id, session_id, question, answer, json.dumps(citations), question_type)
        )
        result = cursor.fetchone()
        conn.commit()
        return {"id": result[0], "timestamp": result[1]}
    finally:
        cursor.close()
        release_db_connection(conn)
```

---

## Summary

This data model defines three primary database tables (**users**, **conversations**, **translations**) with flexible JSONB columns for user backgrounds and conversation citations. The schema supports both authenticated and anonymous users, enabling conversation tracking across signup/signin flows. The translations table caches translated content to reduce API costs. Text chunks for RAG are stored in Qdrant Cloud (reused from 001-hackathon-app), maintaining separation between vector search and relational data.

**Key Design Decisions**:
- JSONB columns for flexibility and agile development
- Nullable user_id to support anonymous conversations
- ON DELETE SET NULL to preserve conversation history
- Indexes on frequently queried columns (email, user_id, session_id, timestamp)
- CHECK constraint for question_type enum values

**Next Steps**: Implement database service layer (`backend/src/services/db_service.py`) with connection pooling, CRUD operations, and error handling.
