"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[2568],{1249:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>a,contentTitle:()=>t,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"review/next-steps","title":"Course Review & Next Steps in Physical AI","description":"Comprehensive review of Physical AI & Humanoid Robotics course modules, key concepts consolidation, advanced topics roadmap, career paths in robotics, and next steps for building your robotics portfolio.","source":"@site/docs/review/next-steps.md","sourceDirName":"review","slug":"/review/next-steps","permalink":"/hackathon-book/docs/review/next-steps","draft":false,"unlisted":false,"editUrl":"https://github.com/MuhammadAhmed-Professional/hackathon-book/tree/master/frontend/docs/review/next-steps.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"next-steps","title":"Course Review & Next Steps in Physical AI","sidebar_label":"Review & Next Steps","sidebar_position":2,"description":"Comprehensive review of Physical AI & Humanoid Robotics course modules, key concepts consolidation, advanced topics roadmap, career paths in robotics, and next steps for building your robotics portfolio.","keywords":["robotics career","physical ai","humanoid robotics","ros2 learning path","robotics research","robotics portfolio","graduate programs robotics"]}}');var r=i(4848),o=i(8453);const l={id:"next-steps",title:"Course Review & Next Steps in Physical AI",sidebar_label:"Review & Next Steps",sidebar_position:2,description:"Comprehensive review of Physical AI & Humanoid Robotics course modules, key concepts consolidation, advanced topics roadmap, career paths in robotics, and next steps for building your robotics portfolio.",keywords:["robotics career","physical ai","humanoid robotics","ros2 learning path","robotics research","robotics portfolio","graduate programs robotics"]},t="Course Review & Next Steps in Physical AI",a={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Module-by-Module Recap",id:"module-by-module-recap",level:2},{value:"Module 1: ROS 2 - The Robotic Nervous System",id:"module-1-ros-2---the-robotic-nervous-system",level:3},{value:"Module 2: Gazebo &amp; Unity - The Digital Twin",id:"module-2-gazebo--unity---the-digital-twin",level:3},{value:"Module 3: NVIDIA Isaac - The AI-Robot Brain",id:"module-3-nvidia-isaac---the-ai-robot-brain",level:3},{value:"Module 4: Vision-Language-Action (VLA) - The Cognitive Layer",id:"module-4-vision-language-action-vla---the-cognitive-layer",level:3},{value:"Skills Consolidation: What You Can Build Now",id:"skills-consolidation-what-you-can-build-now",level:2},{value:"1. Autonomous Delivery Robot",id:"1-autonomous-delivery-robot",level:3},{value:"2. Object Manipulation System",id:"2-object-manipulation-system",level:3},{value:"3. Humanoid Balance Controller",id:"3-humanoid-balance-controller",level:3},{value:"Advanced Topics Roadmap",id:"advanced-topics-roadmap",level:2},{value:"1. Deep Reinforcement Learning for Locomotion",id:"1-deep-reinforcement-learning-for-locomotion",level:3},{value:"2. Sim-to-Real Transfer",id:"2-sim-to-real-transfer",level:3},{value:"3. Whole-Body Control (WBC)",id:"3-whole-body-control-wbc",level:3},{value:"4. Embodied Foundation Models",id:"4-embodied-foundation-models",level:3},{value:"Research Directions in Physical AI",id:"research-directions-in-physical-ai",level:2},{value:"1. Bipedal Locomotion",id:"1-bipedal-locomotion",level:3},{value:"2. Dexterous Manipulation",id:"2-dexterous-manipulation",level:3},{value:"3. Human-Robot Interaction",id:"3-human-robot-interaction",level:3},{value:"4. Sim-to-Real Transfer",id:"4-sim-to-real-transfer",level:3},{value:"Career Paths in Robotics",id:"career-paths-in-robotics",level:2},{value:"1. Robotics Software Engineer",id:"1-robotics-software-engineer",level:3},{value:"2. Robotics Research Scientist",id:"2-robotics-research-scientist",level:3},{value:"3. Hardware-Software Integration Engineer",id:"3-hardware-software-integration-engineer",level:3},{value:"Graduate Programs in Robotics",id:"graduate-programs-in-robotics",level:2},{value:"Top Programs (2025 Rankings)",id:"top-programs-2025-rankings",level:3},{value:"Application Tips",id:"application-tips",level:3},{value:"Industry Certifications",id:"industry-certifications",level:2},{value:"Building Your Robotics Portfolio",id:"building-your-robotics-portfolio",level:2},{value:"1. Open-Source Contributions",id:"1-open-source-contributions",level:3},{value:"2. Personal Projects",id:"2-personal-projects",level:3},{value:"3. Kaggle/Competition Participation",id:"3-kagglecompetition-participation",level:3},{value:"4. Blog Posts / YouTube",id:"4-blog-posts--youtube",level:3},{value:"Community Resources",id:"community-resources",level:2},{value:"Conferences",id:"conferences",level:3},{value:"Online Communities",id:"online-communities",level:3},{value:"Podcasts",id:"podcasts",level:3},{value:"Newsletters",id:"newsletters",level:3},{value:"The Road Ahead: Your Next 12 Months",id:"the-road-ahead-your-next-12-months",level:2},{value:"Months 1-3: Solidify Foundations",id:"months-1-3-solidify-foundations",level:3},{value:"Months 4-6: Specialize",id:"months-4-6-specialize",level:3},{value:"Months 7-9: Real Hardware",id:"months-7-9-real-hardware",level:3},{value:"Months 10-12: Career Preparation",id:"months-10-12-career-preparation",level:3},{value:"Final Thoughts: The Future of Physical AI",id:"final-thoughts-the-future-of-physical-ai",level:2},{value:"Acknowledgments",id:"acknowledgments",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"course-review--next-steps-in-physical-ai",children:"Course Review & Next Steps in Physical AI"})}),"\n",(0,r.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsx)(e.p,{children:"Congratulations on completing this comprehensive journey through Physical AI and Humanoid Robotics! This final chapter consolidates everything you've learned, provides a clear roadmap for advanced study, and guides you toward building a career in this transformative field."}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"What You've Accomplished"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Built production-grade ROS 2 systems for humanoid robots"}),"\n",(0,r.jsx)(e.li,{children:"Simulated complex robot behaviors in Gazebo and NVIDIA Isaac Sim"}),"\n",(0,r.jsx)(e.li,{children:"Deployed hardware-accelerated AI perception with Isaac ROS"}),"\n",(0,r.jsx)(e.li,{children:"Integrated vision, language, and action into autonomous systems"}),"\n",(0,r.jsx)(e.li,{children:"Tested and validated safety-critical robotics software"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"This knowledge positions you at the frontier of Physical AI\u2014the next paradigm shift after generative AI, where intelligence meets embodiment."}),"\n",(0,r.jsx)(e.h2,{id:"module-by-module-recap",children:"Module-by-Module Recap"}),"\n",(0,r.jsx)(e.h3,{id:"module-1-ros-2---the-robotic-nervous-system",children:"Module 1: ROS 2 - The Robotic Nervous System"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Core Concepts Mastered"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ROS 2 Architecture"}),": DDS-based publish/subscribe, real-time communication, distributed computing"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Communication Patterns"}),":","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Topics"}),": Continuous sensor streams (cameras, IMU, LiDAR)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Services"}),": Request/response (get pose, calibrate sensor)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Actions"}),": Long-running tasks with feedback (navigate, grasp)"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Python Integration (rclpy)"}),": Node lifecycle, launch files, parameter servers"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"URDF Modeling"}),": Kinematic chains, joint types, inertial properties for humanoid robots"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Key Skills Acquired"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# You can now build complete ROS 2 packages\nclass HumanoidController(Node):\n    def __init__(self):\n        super().__init__('humanoid_controller')\n\n        # Publishers for joint commands\n        self.joint_pub = self.create_publisher(JointTrajectory, '/joint_trajectory', 10)\n\n        # Subscribers for sensor data\n        self.imu_sub = self.create_subscription(Imu, '/imu/data', self.imu_callback, 10)\n\n        # Action clients for high-level tasks\n        self.nav_client = ActionClient(self, NavigateToPose, 'navigate_to_pose')\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Real-World Applications"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Boston Dynamics Spot"}),": Uses ROS for sensor integration and high-level planning"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"NASA Mars Rovers"}),": ROS-based software for terrain navigation and instrument control"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Agility Robotics Digit"}),": Humanoid delivery robot with ROS 2 middleware"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"What's Next"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Advanced ROS 2"}),": Component nodes, lifecycle management, QoS tuning"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Multi-Robot Systems"}),": Fleet coordination, distributed SLAM"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ROS 2 Control"}),": Hardware interfaces, controllers (PID, MPC)"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"module-2-gazebo--unity---the-digital-twin",children:"Module 2: Gazebo & Unity - The Digital Twin"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Core Concepts Mastered"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Physics Simulation"}),": Rigid body dynamics, collision detection, friction models"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"URDF vs SDF"}),": When to use robot descriptions vs. simulation-specific formats"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sensor Simulation"}),": LiDAR, depth cameras, IMUs with realistic noise models"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Unity Integration"}),": Photorealistic rendering, synthetic data generation"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Key Skills Acquired"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'\x3c!-- You can now create accurate SDF worlds --\x3e\n<sdf version="1.9">\n  <world name="humanoid_testbed">\n    <physics type="ode">\n      <real_time_update_rate>1000</real_time_update_rate>\n      <max_step_size>0.001</max_step_size>\n    </physics>\n\n    <model name="humanoid">\n      <link name="torso">\n        <inertial>\n          <mass>15.0</mass>\n          <inertia>\n            <ixx>0.5</ixx><iyy>0.8</iyy><izz>0.6</izz>\n          </inertia>\n        </inertial>\n        <collision name="collision">\n          <geometry><box><size>0.3 0.4 0.6</size></box></geometry>\n        </collision>\n      </link>\n    </model>\n  </world>\n</sdf>\n'})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Real-World Applications"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Tesla Optimus"}),": Trained in simulation before hardware deployment"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Agility Robotics"}),": Uses Gazebo for gait development and testing"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Google Robotics"}),": Synthetic data from Unity for manipulation tasks"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"What's Next"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"MuJoCo"}),": Physics engine optimized for contact-rich tasks (manipulation)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Isaac Sim Domain Randomization"}),": Generate diverse training data for sim-to-real"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Digital Twin Ecosystems"}),": NVIDIA Omniverse, AWS RoboMaker"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"module-3-nvidia-isaac---the-ai-robot-brain",children:"Module 3: NVIDIA Isaac - The AI-Robot Brain"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Core Concepts Mastered"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Isaac Sim"}),": Photorealistic simulation on Omniverse, USD workflows"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Isaac ROS"}),": GPU-accelerated VSLAM, AprilTags, stereo depth processing"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Visual SLAM"}),": Real-time localization and mapping from cameras"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Nav2"}),": Global planners (A*, Dijkstra), local planners (DWA, TEB), recovery behaviors"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Key Skills Acquired"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# You can now build GPU-accelerated perception pipelines\nfrom isaac_ros_visual_slam import VisualSlamNode\nfrom nav2_simple_commander.robot_navigator import BasicNavigator\n\nclass AutonomousHumanoid(Node):\n    def __init__(self):\n        # Isaac ROS VSLAM for localization\n        self.vslam = VisualSlamNode()\n\n        # Nav2 for path planning\n        self.navigator = BasicNavigator()\n\n    def navigate_to_kitchen(self):\n        goal_pose = PoseStamped()\n        goal_pose.pose.position.x = 5.0\n        goal_pose.pose.position.y = 3.0\n\n        self.navigator.goToPose(goal_pose)\n\n        while not self.navigator.isTaskComplete():\n            feedback = self.navigator.getFeedback()\n            print(f"Distance remaining: {feedback.distance_remaining}m")\n'})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Real-World Applications"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Unitree G1"}),": Humanoid robot using Isaac ROS for perception"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"NVIDIA Carter"}),": Autonomous delivery robot with Isaac stack"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"BMW Factory Robots"}),": Isaac Sim for digital twin validation"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"What's Next"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Isaac Manipulator"}),": GPU-accelerated motion planning for arms"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Isaac Replicator"}),": Synthetic data generation for training perception models"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Isaac Cortex"}),": Behavior trees and task coordination"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"module-4-vision-language-action-vla---the-cognitive-layer",children:"Module 4: Vision-Language-Action (VLA) - The Cognitive Layer"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Core Concepts Mastered"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Speech Recognition"}),": OpenAI Whisper for voice commands"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"LLM Planning"}),": Using GPT-4 to decompose tasks into robot actions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Prompt Engineering"}),": Designing prompts for safe, executable plans"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Multi-Modal Integration"}),": Combining vision, language, and action"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Key Skills Acquired"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# You can now build voice-controlled autonomous robots\nclass VoiceControlledRobot(Node):\n    def __init__(self):\n        self.whisper_client = WhisperClient()  # Speech recognition\n        self.llm_planner = GPT4Planner()       # Task planning\n        self.nav_client = Nav2Client()         # Navigation\n\n    def execute_voice_command(self, audio):\n        # 1. Speech to text\n        command = self.whisper_client.transcribe(audio)\n        # \u2192 "Go to the kitchen and bring me a water bottle"\n\n        # 2. Plan with LLM\n        plan = self.llm_planner.generate_plan(command)\n        # \u2192 [navigate("kitchen"), detect("water_bottle"), grasp(), navigate("user")]\n\n        # 3. Execute actions\n        for action in plan:\n            self.execute_action(action)\n'})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Real-World Applications"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Figure 01 + OpenAI"}),": Humanoid with GPT-4 for task understanding"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Google RT-2"}),": Vision-language-action model for manipulation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Tesla Optimus"}),": Voice-controlled task execution (roadmap)"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"What's Next"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Embodied Foundation Models"}),": RT-X, PaLM-E, Octo"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"End-to-End VLA"}),": Train single models for perception \u2192 planning \u2192 control"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Multi-Robot Collaboration"}),": Coordinated task execution with natural language"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"skills-consolidation-what-you-can-build-now",children:"Skills Consolidation: What You Can Build Now"}),"\n",(0,r.jsx)(e.p,{children:"After completing this course, you can independently build:"}),"\n",(0,r.jsx)(e.h3,{id:"1-autonomous-delivery-robot",children:"1. Autonomous Delivery Robot"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"System Design"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"Voice Command \u2192 LLM Planner \u2192 Nav2 Path Planner \u2192 Motor Control\n      \u2191              \u2191              \u2191                    \u2191\n   Whisper      GPT-4 API      Isaac ROS VSLAM     ROS 2 Control\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Components"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"ROS 2 navigation stack with obstacle avoidance"}),"\n",(0,r.jsx)(e.li,{children:"Isaac ROS VSLAM for localization"}),"\n",(0,r.jsx)(e.li,{children:"Voice command interface with Whisper"}),"\n",(0,r.jsx)(e.li,{children:"Safety monitors (collision detection, emergency stop)"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Implementation Checklist"}),":"]}),"\n",(0,r.jsxs)(e.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Design humanoid URDF with wheels or legs"]}),"\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Simulate in Gazebo with realistic physics"]}),"\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Integrate depth camera and IMU"]}),"\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Deploy Isaac ROS VSLAM"]}),"\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Configure Nav2 with costmaps"]}),"\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Add voice command parser"]}),"\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Test in simulation and hardware"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"2-object-manipulation-system",children:"2. Object Manipulation System"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"System Design"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"Vision (Camera) \u2192 Object Detection \u2192 Grasp Planning \u2192 Arm Control\n        \u2191              \u2191                  \u2191               \u2191\n   RealSense     YOLOv8/DINO        MoveIt 2      JointTrajectory\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Components"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"ROS 2 perception pipeline (YOLOv8, SegmentAnything)"}),"\n",(0,r.jsx)(e.li,{children:"MoveIt 2 for motion planning"}),"\n",(0,r.jsx)(e.li,{children:"Gripper control with force feedback"}),"\n",(0,r.jsx)(e.li,{children:"Isaac Sim for synthetic grasp training data"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"3-humanoid-balance-controller",children:"3. Humanoid Balance Controller"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"System Design"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"IMU \u2192 State Estimation \u2192 Balance Controller \u2192 Joint Commands\n \u2191           \u2191                  \u2191                    \u2191\nGyro     Kalman Filter       MPC/LQR          Actuators\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Components"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Sensor fusion (IMU + joint encoders)"}),"\n",(0,r.jsx)(e.li,{children:"Model Predictive Control (MPC) for balance"}),"\n",(0,r.jsx)(e.li,{children:"Zero-Moment Point (ZMP) calculations"}),"\n",(0,r.jsx)(e.li,{children:"Gazebo testing with push disturbances"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"advanced-topics-roadmap",children:"Advanced Topics Roadmap"}),"\n",(0,r.jsx)(e.h3,{id:"1-deep-reinforcement-learning-for-locomotion",children:"1. Deep Reinforcement Learning for Locomotion"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Why It Matters"}),": Hand-coding humanoid gaits is brittle. RL learns robust walking from trial-and-error."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Getting Started"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Framework"}),": Isaac Gym (GPU-accelerated physics)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Algorithm"}),": Proximal Policy Optimization (PPO)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Paper"}),': "Learning to Walk in Minutes Using Massively Parallel Deep RL" (Rudin et al., 2022)']}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Implementation Steps"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# Example: Train humanoid walking with Isaac Gym\nfrom isaacgym import gymapi\nfrom stable_baselines3 import PPO\n\n# 1. Create parallel simulations (4096 robots)\ngym = gymapi.acquire_gym()\nenvs = [gym.create_env(sim, env_config) for _ in range(4096)]\n\n# 2. Define reward function\ndef compute_reward(obs, action):\n    forward_velocity = obs['base_vel'][0]\n    energy_cost = np.sum(action ** 2)\n    alive_bonus = 1.0\n    return forward_velocity - 0.01 * energy_cost + alive_bonus\n\n# 3. Train PPO\nmodel = PPO(\"MlpPolicy\", env, verbose=1)\nmodel.learn(total_timesteps=10_000_000)\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Resources"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://arxiv.org/abs/2108.10470",children:"Isaac Gym Paper"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://github.com/leggedrobotics/legged_gym",children:"Legged Gym Framework"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://github.com/leggedrobotics/rsl_rl",children:"RSL RL Library"})}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"2-sim-to-real-transfer",children:"2. Sim-to-Real Transfer"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"The Problem"}),": Robots trained in simulation fail in the real world due to modeling errors (friction, latency, sensor noise)."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Domain Randomization"}),": Randomize physics parameters during training"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"System Identification"}),": Measure real-world parameters, update simulation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Residual Learning"}),": Train in sim, fine-tune on real robot"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Example: Domain Randomization"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# Randomize physics in Isaac Sim\nimport omni.isaac.core.utils.prims as prim_utils\n\ndef randomize_physics():\n    # Randomize mass\n    mass = np.random.uniform(10.0, 20.0)\n    prim_utils.set_prim_attribute("/World/robot/torso", "physics:mass", mass)\n\n    # Randomize friction\n    friction = np.random.uniform(0.5, 1.5)\n    prim_utils.set_prim_attribute("/World/ground", "physics:friction", friction)\n\n    # Randomize joint damping\n    damping = np.random.uniform(0.1, 0.5)\n    for joint in robot.joints:\n        joint.set_damping(damping)\n'})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Recommended Reading"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:'"Sim-to-Real Transfer of Robotic Control with Dynamics Randomization" (OpenAI, 2018)'}),"\n",(0,r.jsx)(e.li,{children:'"Learning Dexterous In-Hand Manipulation" (OpenAI, 2019)'}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"3-whole-body-control-wbc",children:"3. Whole-Body Control (WBC)"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Why It Matters"}),": Humanoids must coordinate 30+ joints for locomotion + manipulation simultaneously."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Mathematical Foundation"}),":\nSolve quadratic program (QP) at every timestep:"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"minimize:   ||q\u0308_desired - q\u0308||\xb2  (joint accelerations)\nsubject to: M(q)q\u0308 + C(q,q\u0307) = \u03c4 + J^T F  (dynamics)\n            J_contact q\u0308 + J\u0307_contact q\u0307 = 0  (contact constraints)\n            \u03c4_min \u2264 \u03c4 \u2264 \u03c4_max            (torque limits)\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Tools"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Pinocchio"}),": Fast rigid-body dynamics library"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"OSQP"}),": Efficient QP solver"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Pink"}),": Python library for humanoid WBC"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Example: Task-Space Control"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import pinocchio as pin\nimport pink\n\n# Define tasks\ntasks = [\n    pink.tasks.FrameTask("left_foot", position=[0, 0.1, 0], weight=1.0),\n    pink.tasks.FrameTask("right_foot", position=[0, -0.1, 0], weight=1.0),\n    pink.tasks.PostureTask(q_ref=neutral_posture, weight=0.1),\n]\n\n# Solve WBC at 1 kHz\nconfiguration = pink.solve_ik(tasks, dt=0.001)\n'})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Resources"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://github.com/stephane-caron/pink",children:"Pink Library"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://gepettoweb.laas.fr/doc/stack-of-tasks/pinocchio/master/doxygen-html/",children:"Pinocchio Tutorials"})}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"4-embodied-foundation-models",children:"4. Embodied Foundation Models"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"The Future"}),": Single models trained on millions of robot trajectories, generalizing to new tasks with zero-shot or few-shot learning."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Key Models (2024-2025)"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RT-2"})," (Google): Vision-language-action with 175B parameters"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"PaLM-E"})," (Google): 562B multimodal model for embodied reasoning"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Octo"})," (UC Berkeley): Open-source generalist robot policy"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u03c0\u2080"})," (Physical Intelligence): Generalist humanoid policy"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"How to Use Octo"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"from octo.model import OctoModel\n\n# Load pre-trained model\nmodel = OctoModel.from_pretrained(\"hf://rail-berkeley/octo-base\")\n\n# Zero-shot inference on your robot\nobservation = {\n    'image': camera_image,  # (224, 224, 3)\n    'proprio': joint_positions,  # (7,)\n}\n\naction = model.predict(observation, task_description=\"pick up the red block\")\n# \u2192 action: [dx, dy, dz, gripper]\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Resources"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://arxiv.org/abs/2405.12213",children:"Octo Paper"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/",children:"RT-2 Blog Post"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://robotics-transformer-x.github.io/",children:"Open X-Embodiment Dataset"})}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"research-directions-in-physical-ai",children:"Research Directions in Physical AI"}),"\n",(0,r.jsx)(e.p,{children:"If you're interested in pursuing research (Master's, PhD, or industry R&D):"}),"\n",(0,r.jsx)(e.h3,{id:"1-bipedal-locomotion",children:"1. Bipedal Locomotion"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Open Problems"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Robust walking on unstructured terrain (stairs, rubble, slopes)"}),"\n",(0,r.jsx)(e.li,{children:"Energy-efficient gaits matching human performance"}),"\n",(0,r.jsx)(e.li,{children:"Dynamic maneuvers (jumping, running, recovery from falls)"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Leading Labs"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"MIT Biomimetics Lab (Sangbae Kim)"}),"\n",(0,r.jsx)(e.li,{children:"ETH Zurich RSL (Marco Hutter)"}),"\n",(0,r.jsx)(e.li,{children:"UC Berkeley HiPeRLab (Koushil Sreenath)"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"2-dexterous-manipulation",children:"2. Dexterous Manipulation"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Open Problems"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"In-hand manipulation with human-level dexterity"}),"\n",(0,r.jsx)(e.li,{children:"Generalizing grasps to novel objects"}),"\n",(0,r.jsx)(e.li,{children:"Contact-rich tasks (assembly, tool use)"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Leading Labs"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Stanford IPRL (Karen Liu)"}),"\n",(0,r.jsx)(e.li,{children:"CMU Robotics Institute (Oliver Kroemer)"}),"\n",(0,r.jsx)(e.li,{children:"UC Berkeley RAIL (Sergey Levine)"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"3-human-robot-interaction",children:"3. Human-Robot Interaction"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Open Problems"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Natural language grounding to robot actions"}),"\n",(0,r.jsx)(e.li,{children:"Predicting human intent from motion"}),"\n",(0,r.jsx)(e.li,{children:"Safe physical human-robot collaboration"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Leading Labs"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"MIT CSAIL (Daniela Rus)"}),"\n",(0,r.jsx)(e.li,{children:"Stanford HRI (Karen Liu)"}),"\n",(0,r.jsx)(e.li,{children:"TU Munich (Sami Haddadin)"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"4-sim-to-real-transfer",children:"4. Sim-to-Real Transfer"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Open Problems"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Zero-gap transfer (simulation = reality)"}),"\n",(0,r.jsx)(e.li,{children:"Real-time physics parameter estimation"}),"\n",(0,r.jsx)(e.li,{children:"Learning world models from minimal real data"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Leading Labs"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"UC Berkeley RAIL (Sergey Levine)"}),"\n",(0,r.jsx)(e.li,{children:"Google DeepMind Robotics"}),"\n",(0,r.jsx)(e.li,{children:"NVIDIA Research"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"career-paths-in-robotics",children:"Career Paths in Robotics"}),"\n",(0,r.jsx)(e.h3,{id:"1-robotics-software-engineer",children:"1. Robotics Software Engineer"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Responsibilities"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Develop ROS 2 perception, planning, and control systems"}),"\n",(0,r.jsx)(e.li,{children:"Integrate sensors, actuators, and AI models"}),"\n",(0,r.jsx)(e.li,{children:"Test and deploy on real hardware"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Companies Hiring"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Humanoid Robotics"}),": Figure AI, Agility Robotics, Tesla, 1X Technologies"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Manipulation"}),": Covariant, Dexterity, Robust.AI"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Autonomous Vehicles"}),": Waymo, Cruise, Aurora, Zoox"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Industrial"}),": ABB, FANUC, Boston Dynamics"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Salary Range"}),": $120k - $250k (US, 2024)"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Required Skills"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"ROS 2, C++/Python"}),"\n",(0,r.jsx)(e.li,{children:"Computer vision (OpenCV, PyTorch)"}),"\n",(0,r.jsx)(e.li,{children:"Path planning algorithms (A*, RRT)"}),"\n",(0,r.jsx)(e.li,{children:"Hardware debugging (oscilloscopes, CAN bus)"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"2-robotics-research-scientist",children:"2. Robotics Research Scientist"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Responsibilities"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Publish papers at top conferences (RSS, ICRA, CoRL)"}),"\n",(0,r.jsx)(e.li,{children:"Develop novel algorithms (learning, control, perception)"}),"\n",(0,r.jsx)(e.li,{children:"Collaborate with academic labs"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Companies Hiring"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"NVIDIA Research, Google DeepMind, Meta AI"}),"\n",(0,r.jsx)(e.li,{children:"Boston Dynamics AI Institute"}),"\n",(0,r.jsx)(e.li,{children:"Toyota Research Institute (TRI)"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Salary Range"}),": $150k - $400k (US, 2024)"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Required Skills"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"PhD in Robotics/CS/ML"}),"\n",(0,r.jsx)(e.li,{children:"Publications at top venues"}),"\n",(0,r.jsx)(e.li,{children:"Deep RL, optimal control, or vision expertise"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"3-hardware-software-integration-engineer",children:"3. Hardware-Software Integration Engineer"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Responsibilities"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Design PCBs for motor drivers, sensors"}),"\n",(0,r.jsx)(e.li,{children:"Write firmware for microcontrollers (STM32, ESP32)"}),"\n",(0,r.jsx)(e.li,{children:"Integrate with ROS 2 via serial, CAN, Ethernet"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Companies Hiring"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Agility Robotics, Figure AI, Tesla Optimus"}),"\n",(0,r.jsx)(e.li,{children:"Apptronik, Sanctuary AI"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Salary Range"}),": $110k - $200k (US, 2024)"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Required Skills"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Embedded C/C++"}),"\n",(0,r.jsx)(e.li,{children:"PCB design (KiCad, Altium)"}),"\n",(0,r.jsx)(e.li,{children:"Communication protocols (CAN, I2C, SPI)"}),"\n",(0,r.jsx)(e.li,{children:"ROS 2 hardware interfaces"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"graduate-programs-in-robotics",children:"Graduate Programs in Robotics"}),"\n",(0,r.jsx)(e.h3,{id:"top-programs-2025-rankings",children:"Top Programs (2025 Rankings)"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"1. Carnegie Mellon University (CMU)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Robotics Institute (RI)"}),": World's #1 robotics program"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"MS in Robotics"}),": 2 years, highly competitive (5% acceptance)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Strengths"}),": Manipulation, autonomous vehicles, learning"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Notable Faculty"}),": Chris Atkeson, Katerina Fragkiadaki, Deepak Pathak"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2. MIT CSAIL"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"MS/PhD in EECS with Robotics Focus"})}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Strengths"}),": Bipedal locomotion, soft robotics, HRI"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Notable Faculty"}),": Russ Tedrake, Daniela Rus, Sangbae Kim"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3. Stanford University"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"MS in Computer Science (AI/Robotics Track)"})}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Strengths"}),": Manipulation, learning, embodied AI"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Notable Faculty"}),": Karen Liu, Fei-Fei Li, Chelsea Finn"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4. UC Berkeley"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"EECS MS/PhD with RAIL/HiPeRLab"})}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Strengths"}),": Deep RL, sim-to-real, humanoid control"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Notable Faculty"}),": Sergey Levine, Pieter Abbeel, Koushil Sreenath"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"5. ETH Zurich (Europe)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"MS in Robotics, Systems and Control"})}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Strengths"}),": Legged locomotion, flying robots, WBC"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Notable Faculty"}),": Marco Hutter, Roland Siegwart"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"application-tips",children:"Application Tips"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Strong Math Background"}),": Linear algebra, optimization, probability"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Research Experience"}),": Publications, open-source contributions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Recommendation Letters"}),": From professors/industry mentors in robotics"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Statement of Purpose"}),": Specific research interests, alignment with faculty"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"GRE"}),": Often required, aim for >165 Quant"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"industry-certifications",children:"Industry Certifications"}),"\n",(0,r.jsx)(e.p,{children:"While not required, certifications demonstrate expertise:"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"1. ROS 2 Developer Certification (The Construct)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Online courses + exam"}),"\n",(0,r.jsx)(e.li,{children:"Covers ROS 2 Humble fundamentals"}),"\n",(0,r.jsx)(e.li,{children:"Cost: $500"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2. NVIDIA Deep Learning Institute (DLI)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:'"Building Robot Applications with NVIDIA Isaac"'}),"\n",(0,r.jsx)(e.li,{children:"Hands-on Isaac Sim and Isaac ROS"}),"\n",(0,r.jsx)(e.li,{children:"Cost: $90/course"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3. Certified Safety Professional (CSP)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"For robots working near humans"}),"\n",(0,r.jsx)(e.li,{children:"Covers ISO 10218 (robot safety standards)"}),"\n",(0,r.jsx)(e.li,{children:"Cost: $350"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"building-your-robotics-portfolio",children:"Building Your Robotics Portfolio"}),"\n",(0,r.jsx)(e.h3,{id:"1-open-source-contributions",children:"1. Open-Source Contributions"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Why It Matters"}),": Demonstrates real-world collaboration and code quality."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Where to Contribute"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ROS 2 Core"}),": Bug fixes, documentation improvements"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Nav2"}),": New planners, recovery behaviors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"MoveIt 2"}),": Motion planning algorithms"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Isaac ROS"}),": Hardware compatibility, bug reports"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"How to Start"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:'Find issues labeled "good first issue" on GitHub'}),"\n",(0,r.jsx)(e.li,{children:"Set up development environment"}),"\n",(0,r.jsx)(e.li,{children:"Submit pull request with tests"}),"\n",(0,r.jsx)(e.li,{children:"Engage with maintainer feedback"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"2-personal-projects",children:"2. Personal Projects"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Showcase Examples"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Autonomous Lawn Mower"}),": ROS 2 + GPS + Nav2"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Bartender Robot"}),": Manipulation + object detection"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Humanoid Walker"}),": Gazebo sim + balance controller"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Portfolio Site Structure"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"yourname.github.io/\n\u251c\u2500\u2500 index.html (overview)\n\u251c\u2500\u2500 projects/\n\u2502   \u251c\u2500\u2500 humanoid-walker/\n\u2502   \u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2502   \u251c\u2500\u2500 demo.mp4\n\u2502   \u2502   \u2514\u2500\u2500 source-code/\n\u2502   \u2514\u2500\u2500 bartender-robot/\n\u251c\u2500\u2500 publications/ (if any)\n\u2514\u2500\u2500 resume.pdf\n"})}),"\n",(0,r.jsx)(e.h3,{id:"3-kagglecompetition-participation",children:"3. Kaggle/Competition Participation"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"DARPA Subterranean Challenge"})," (past, study solutions)"]}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"RoboCup Humanoid League"})}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Amazon Robotics Challenge"})," (archived, study approaches)"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"4-blog-posts--youtube",children:"4. Blog Posts / YouTube"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Content Ideas"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:'"How I Built a ROS 2 Humanoid from Scratch"'}),"\n",(0,r.jsx)(e.li,{children:'"Deploying Isaac ROS VSLAM on Jetson Orin"'}),"\n",(0,r.jsx)(e.li,{children:'"Zero to Navigation in 30 Minutes with Nav2"'}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Platforms"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Medium"}),": Written tutorials"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"YouTube"}),": Video demos"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Twitter/X"}),": Thread-style explanations"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"community-resources",children:"Community Resources"}),"\n",(0,r.jsx)(e.h3,{id:"conferences",children:"Conferences"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RSS"})," (Robotics: Science and Systems): Top academic conference"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ICRA"})," (IEEE Intl. Conf. on Robotics and Automation): Largest robotics conference"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"CoRL"})," (Conference on Robot Learning): Learning-focused"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"IROS"})," (IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems)"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Attending as a Student"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Student volunteer programs (free registration)"}),"\n",(0,r.jsx)(e.li,{children:"Poster sessions (network with authors)"}),"\n",(0,r.jsx)(e.li,{children:"Workshops (hands-on tutorials)"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"online-communities",children:"Online Communities"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ROS Discourse"}),": Official ROS forum (discourse.ros.org)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"r/ROS"}),": Reddit community (50k+ members)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Robotics Discord"}),": Real-time Q&A with experts"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Isaac Sim Forums"}),": NVIDIA-hosted support"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"podcasts",children:"Podcasts"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Robot Talk"}),": Interviews with robotics researchers"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sense Think Act"}),": Deep dives into robot perception"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"The Robot Brains Podcast"}),": Industry leaders and academics"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"newsletters",children:"Newsletters"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"The Robot Report"}),": Weekly industry news"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"AI Robotics Digest"}),": Research paper summaries"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ROS News Weekly"}),": ROS ecosystem updates"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"the-road-ahead-your-next-12-months",children:"The Road Ahead: Your Next 12 Months"}),"\n",(0,r.jsx)(e.h3,{id:"months-1-3-solidify-foundations",children:"Months 1-3: Solidify Foundations"}),"\n",(0,r.jsxs)(e.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Rebuild all course projects from scratch (no copy-paste)"]}),"\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Contribute 3 pull requests to open-source robotics projects"]}),"\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Write blog post explaining one complex concept (VSLAM, Nav2, etc.)"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"months-4-6-specialize",children:"Months 4-6: Specialize"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Pick one domain"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Locomotion"}),": Implement PPO for humanoid walking in Isaac Gym"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Manipulation"}),": Build MoveIt 2 pipeline for pick-and-place"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Navigation"}),": Extend Nav2 with custom planner or controller"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Deliverable"}),": Working demo + GitHub repo + documentation"]}),"\n",(0,r.jsx)(e.h3,{id:"months-7-9-real-hardware",children:"Months 7-9: Real Hardware"}),"\n",(0,r.jsxs)(e.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Purchase/access real robot (Turtlebot4, Stretch, or build custom)"]}),"\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Port simulation code to hardware"]}),"\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Document sim-to-real transfer challenges"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"months-10-12-career-preparation",children:"Months 10-12: Career Preparation"}),"\n",(0,r.jsxs)(e.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Apply to graduate programs (if pursuing MS/PhD)"]}),"\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Prepare portfolio website with 3+ projects"]}),"\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Network on LinkedIn/Twitter with robotics professionals"]}),"\n",(0,r.jsxs)(e.li,{className:"task-list-item",children:[(0,r.jsx)(e.input,{type:"checkbox",disabled:!0})," ","Apply to robotics companies (target 10+ applications)"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"final-thoughts-the-future-of-physical-ai",children:"Final Thoughts: The Future of Physical AI"}),"\n",(0,r.jsx)(e.p,{children:"We stand at the threshold of a robotic revolution. Just as ChatGPT democratized language AI, embodied foundation models will democratize robotics. In 5 years, you may:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Fine-tune"})," a pre-trained humanoid policy for your specific task (like fine-tuning GPT today)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Deploy"})," robots in hours instead of months"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Collaborate"})," with robots that understand natural language and visual context"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"But domain expertise will still matter."})," The engineers who understand:"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"How ROS 2 enables real-time communication"}),"\n",(0,r.jsx)(e.li,{children:"Why Gazebo's ODE solver behaves differently than MuJoCo"}),"\n",(0,r.jsx)(e.li,{children:"When to use visual SLAM vs. LiDAR SLAM"}),"\n",(0,r.jsx)(e.li,{children:"How to debug CAN bus communication at 3 AM"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"...will remain indispensable."}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"You now have that expertise."})," Go build the future."]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"acknowledgments",children:"Acknowledgments"}),"\n",(0,r.jsx)(e.p,{children:"This course drew inspiration from:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"MIT 6.4210"})," (Robotic Manipulation) - Prof. Russ Tedrake"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Stanford CS237B"})," (Principles of Robot Autonomy II)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"CMU 16-899"})," (Adaptive Control and Reinforcement Learning)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ETH Zurich RSL"})," (Legged Robotics Course)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"Special thanks to the open-source robotics community\u2014especially ROS, Gazebo, and Isaac teams\u2014for making this education possible."}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Additional Resources"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://docs.ros.org/en/humble/",children:"ROS 2 Official Documentation"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/",children:"NVIDIA Isaac Documentation"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://github.com/kiloreux/awesome-robotics",children:"Awesome Robotics List"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://paperswithcode.com/area/robotics",children:"Papers With Code - Robotics"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://robotics.stackexchange.com/",children:"Robotics Stack Exchange"})}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Course Feedback"}),": We'd love to hear how this course impacted your journey. Share your projects, questions, or suggestions at [",(0,r.jsx)(e.a,{href:"mailto:course-feedback@example.com",children:"course-feedback@example.com"}),"]"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Good luck, and welcome to the future of Physical AI!"})})]})}function h(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>l,x:()=>t});var s=i(6540);const r={},o=s.createContext(r);function l(n){const e=s.useContext(o);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function t(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:l(n.components),s.createElement(o.Provider,{value:e},n.children)}}}]);