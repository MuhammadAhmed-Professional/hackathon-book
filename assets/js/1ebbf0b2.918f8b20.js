"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[8015],{8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var r=i(6540);const s={},t=r.createContext(s);function l(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),r.createElement(t.Provider,{value:n},e.children)}},9102:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>a});const r=JSON.parse('{"id":"module3/performance-optimization","title":"Performance Optimization for Physical AI Systems","description":"Master CPU/GPU profiling, ROS 2 tuning, and inference optimization to achieve real-time performance in humanoid robotics","source":"@site/docs/module3/performance-optimization.md","sourceDirName":"module3","slug":"/module3/performance-optimization","permalink":"/hackathon-book/docs/module3/performance-optimization","draft":false,"unlisted":false,"editUrl":"https://github.com/MuhammadAhmed-Professional/hackathon-book/tree/master/frontend/docs/module3/performance-optimization.md","tags":[{"inline":true,"label":"performance","permalink":"/hackathon-book/docs/tags/performance"},{"inline":true,"label":"optimization","permalink":"/hackathon-book/docs/tags/optimization"},{"inline":true,"label":"profiling","permalink":"/hackathon-book/docs/tags/profiling"},{"inline":true,"label":"gpu","permalink":"/hackathon-book/docs/tags/gpu"},{"inline":true,"label":"tensorrt","permalink":"/hackathon-book/docs/tags/tensorrt"},{"inline":true,"label":"ros2","permalink":"/hackathon-book/docs/tags/ros-2"},{"inline":true,"label":"latency","permalink":"/hackathon-book/docs/tags/latency"},{"inline":true,"label":"throughput","permalink":"/hackathon-book/docs/tags/throughput"}],"version":"current","sidebarPosition":4,"frontMatter":{"id":"performance-optimization","title":"Performance Optimization for Physical AI Systems","sidebar_label":"Performance Optimization","sidebar_position":4,"description":"Master CPU/GPU profiling, ROS 2 tuning, and inference optimization to achieve real-time performance in humanoid robotics","tags":["performance","optimization","profiling","gpu","tensorrt","ros2","latency","throughput"]},"sidebar":"tutorialSidebar","previous":{"title":"Jetson Deployment","permalink":"/hackathon-book/docs/module3/jetson-deployment"},"next":{"title":"Module 4: Integration & Advanced Topics - Chapter Summary","permalink":"/hackathon-book/docs/module4/"}}');var s=i(4848),t=i(8453);const l={id:"performance-optimization",title:"Performance Optimization for Physical AI Systems",sidebar_label:"Performance Optimization",sidebar_position:4,description:"Master CPU/GPU profiling, ROS 2 tuning, and inference optimization to achieve real-time performance in humanoid robotics",tags:["performance","optimization","profiling","gpu","tensorrt","ros2","latency","throughput"]},o="Performance Optimization for Physical AI Systems",c={},a=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Conceptual Overview: The Performance Landscape",id:"conceptual-overview-the-performance-landscape",level:2},{value:"1. CPU vs GPU Bottlenecks",id:"1-cpu-vs-gpu-bottlenecks",level:3},{value:"2. Latency vs Throughput Tradeoffs",id:"2-latency-vs-throughput-tradeoffs",level:3},{value:"3. Amdahl&#39;s Law in Robotics",id:"3-amdahls-law-in-robotics",level:3},{value:"Hands-On Section 1: CPU Profiling with perf and Flame Graphs",id:"hands-on-section-1-cpu-profiling-with-perf-and-flame-graphs",level:2},{value:"The Problem: Identifying Hotspots",id:"the-problem-identifying-hotspots",level:3},{value:"Step 1: Profile with <code>perf</code>",id:"step-1-profile-with-perf",level:3},{value:"Step 2: Generate Flame Graph",id:"step-2-generate-flame-graph",level:3},{value:"Step 3: Fix the Bottleneck",id:"step-3-fix-the-bottleneck",level:3},{value:"Hands-On Section 2: GPU Optimization with NVIDIA Nsight",id:"hands-on-section-2-gpu-optimization-with-nvidia-nsight",level:2},{value:"Profiling CUDA Kernels",id:"profiling-cuda-kernels",level:3},{value:"Profile with Nsight Compute",id:"profile-with-nsight-compute",level:3},{value:"Optimized Implementation",id:"optimized-implementation",level:3},{value:"Hands-On Section 3: ROS 2 Performance Tuning",id:"hands-on-section-3-ros-2-performance-tuning",level:2},{value:"QoS Policy Optimization",id:"qos-policy-optimization",level:3},{value:"Zero-Copy Transport (Intra-Process Communication)",id:"zero-copy-transport-intra-process-communication",level:3},{value:"Multi-Threaded Executor for Parallel Callbacks",id:"multi-threaded-executor-for-parallel-callbacks",level:3},{value:"Advanced Topics: TensorRT and Quantization",id:"advanced-topics-tensorrt-and-quantization",level:2},{value:"TensorRT Optimization Pipeline",id:"tensorrt-optimization-pipeline",level:3},{value:"Quantization-Aware Training (QAT)",id:"quantization-aware-training-qat",level:3},{value:"Multi-GPU Scaling for 4-Camera Systems",id:"multi-gpu-scaling-for-4-camera-systems",level:2},{value:"Exercises",id:"exercises",level:2},{value:"Easy (Fundamentals)",id:"easy-fundamentals",level:3},{value:"Medium (Real-World Optimization)",id:"medium-real-world-optimization",level:3},{value:"Hard (Multi-GPU Production System)",id:"hard-multi-gpu-production-system",level:3},{value:"Summary",id:"summary",level:2},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",img:"img",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"performance-optimization-for-physical-ai-systems",children:"Performance Optimization for Physical AI Systems"})}),"\n",(0,s.jsxs)(n.p,{children:['A humanoid robot running at 5 FPS instead of 30 FPS doesn\'t just move slower\u2014it fundamentally cannot balance, grasp objects, or navigate safely. When Tesla\'s Optimus team optimized their perception pipeline from 120ms to 8ms latency, they unlocked closed-loop control frequencies that transformed the robot from "barely walking" to "dynamically stable." ',(0,s.jsx)(n.strong,{children:"Performance optimization is not optional in physical AI\u2014it determines whether your robot works at all."})]}),"\n",(0,s.jsx)(n.p,{children:"In this chapter, you'll master systematic profiling, GPU acceleration, ROS 2 tuning, and inference optimization to achieve the real-time performance humanoid robotics demands. You'll learn to identify bottlenecks using flame graphs, eliminate memory bandwidth constraints, and deploy quantized neural networks running at 200+ FPS on edge hardware."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(n.p,{children:"By completing this chapter, you will be able to:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Profile CPU/GPU bottlenecks"})," using perf, Nsight, and ROS 2 tracing tools"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Optimize ROS 2 nodes"})," for zero-copy transport and multi-threaded execution"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Accelerate inference"})," using TensorRT quantization (FP32 \u2192 INT8) with <2% accuracy loss"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Measure end-to-end latency"})," from sensor capture to actuator command"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Apply Amdahl's Law"})," to identify diminishing returns in parallel optimization"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Implement pipeline parallelism"})," for multi-stage perception systems"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Achieve 4-camera, 60 FPS"})," object detection on NVIDIA Jetson Orin"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Required Knowledge"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"GPU architecture basics (CUDA cores, memory hierarchy, warps)"}),"\n",(0,s.jsx)(n.li,{children:"ROS 2 fundamentals (nodes, topics, executors, QoS)"}),"\n",(0,s.jsxs)(n.li,{children:["Linux command-line profiling (",(0,s.jsx)(n.code,{children:"top"}),", ",(0,s.jsx)(n.code,{children:"htop"}),", ",(0,s.jsx)(n.code,{children:"/proc"})," filesystem)"]}),"\n",(0,s.jsx)(n.li,{children:"Python/C++ proficiency"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Hardware"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"NVIDIA GPU (RTX 3060+ or Jetson Orin Nano)"}),"\n",(0,s.jsx)(n.li,{children:"Ubuntu 20.04/22.04"}),"\n",(0,s.jsx)(n.li,{children:"ROS 2 Humble"}),"\n",(0,s.jsx)(n.li,{children:"16GB+ RAM recommended"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Software"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Install profiling tools\nsudo apt install linux-tools-common linux-tools-generic \\\n                 valgrind graphviz flamegraph\npip install py-spy memory_profiler torch torchvision\n\n# Install NVIDIA tools (for GPU systems)\nsudo apt install nvidia-cuda-toolkit nsight-systems nsight-compute\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"conceptual-overview-the-performance-landscape",children:"Conceptual Overview: The Performance Landscape"}),"\n",(0,s.jsx)(n.h3,{id:"1-cpu-vs-gpu-bottlenecks",children:"1. CPU vs GPU Bottlenecks"}),"\n",(0,s.jsx)(n.p,{children:"Physical AI systems exhibit three primary bottleneck patterns:"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"CPU-Bound"}),": Control logic, state estimation, path planning"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Symptom"}),": High CPU usage (>80%), GPU idle"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Example"}),": Kalman filter running at 1 kHz for IMU fusion"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Solution"}),": Vectorization, multi-threading, C++ over Python"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"GPU-Bound"}),": Inference, image processing, SLAM"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Symptom"}),": GPU utilization >90%, CPU waiting"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Example"}),": YOLOv8 inference on 4K video"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Solution"}),": TensorRT optimization, batch processing, quantization"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Memory-Bound"}),": Data transfer (CPU \u2194 GPU), image copy operations"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Symptom"}),": Low CPU/GPU usage, high PCIe bandwidth"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Example"}),": Copying 4x 1920x1080x3 images to GPU every frame"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Solution"}),": Zero-copy, pinned memory, frame skipping"]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{title:"Critical Insight",type:"warning",children:(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"80% of robotics performance issues are memory bandwidth bottlenecks"}),", not compute. A 4K RGB image (1920\xd71080\xd73 bytes = 6.2 MB) transferred at 30 FPS consumes ",(0,s.jsx)(n.strong,{children:"186 MB/s"}),". Four cameras saturate PCIe Gen3 bandwidth (\u22481 GB/s)."]})}),"\n",(0,s.jsx)(n.h3,{id:"2-latency-vs-throughput-tradeoffs",children:"2. Latency vs Throughput Tradeoffs"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Latency"}),": Time from sensor input \u2192 actuator output (critical for control)\n",(0,s.jsx)(n.strong,{children:"Throughput"}),": Frames processed per second (critical for perception)"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Use Case"}),(0,s.jsx)(n.th,{children:"Priority"}),(0,s.jsx)(n.th,{children:"Target"}),(0,s.jsx)(n.th,{children:"Optimization Strategy"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Whole-body control"})}),(0,s.jsx)(n.td,{children:"Latency"}),(0,s.jsx)(n.td,{children:"<10ms"}),(0,s.jsx)(n.td,{children:"Single-threaded, minimal overhead"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Object detection"})}),(0,s.jsx)(n.td,{children:"Throughput"}),(0,s.jsx)(n.td,{children:"30+ FPS"}),(0,s.jsx)(n.td,{children:"Batching, pipeline parallelism"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Visual servoing"})}),(0,s.jsx)(n.td,{children:"Both"}),(0,s.jsx)(n.td,{children:"<20ms, 60 FPS"}),(0,s.jsx)(n.td,{children:"Asynchronous processing, prediction"})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Example"}),": Humanoid grasping requires <50ms latency (visual feedback \u2192 motor adjustment) but only 15 FPS throughput (perception updates). Over-optimizing throughput to 120 FPS wastes power."]}),"\n",(0,s.jsx)(n.h3,{id:"3-amdahls-law-in-robotics",children:"3. Amdahl's Law in Robotics"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Amdahl's Law"}),": Speedup from parallelizing P% of code with N cores:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Speedup = 1 / ((1 - P) + P/N)\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Robotics Reality"}),": Most perception pipelines have 20-40% serial overhead (preprocessing, synchronization, postprocessing)."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Example"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Serial overhead: 30%"}),"\n",(0,s.jsx)(n.li,{children:"Parallelizable: 70% (image processing)"}),"\n",(0,s.jsxs)(n.li,{children:["8-core CPU: Max speedup = 1 / (0.3 + 0.7/8) = ",(0,s.jsx)(n.strong,{children:"2.8x"})," (not 8x!)"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Implication"}),": Focus first on ",(0,s.jsx)(n.strong,{children:"reducing serial overhead"})," (faster libraries, algorithmic improvements) before adding cores."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"hands-on-section-1-cpu-profiling-with-perf-and-flame-graphs",children:"Hands-On Section 1: CPU Profiling with perf and Flame Graphs"}),"\n",(0,s.jsx)(n.h3,{id:"the-problem-identifying-hotspots",children:"The Problem: Identifying Hotspots"}),"\n",(0,s.jsx)(n.p,{children:"Your ROS 2 navigation stack runs at 5 Hz instead of 20 Hz. Where is the bottleneck?"}),"\n",(0,s.jsxs)(n.h3,{id:"step-1-profile-with-perf",children:["Step 1: Profile with ",(0,s.jsx)(n.code,{children:"perf"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",metastring:'title="Profile ROS 2 node for 30 seconds"',children:"# Launch your node\nros2 run my_robot_nav path_planner &\nNODE_PID=$!\n\n# Profile with perf (requires root or sysctl kernel.perf_event_paranoid=1)\nsudo perf record -F 99 -p $NODE_PID -g -- sleep 30\n\n# Generate report\nsudo perf report --stdio > perf_report.txt\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Sample Output"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"# Overhead  Command   Shared Object       Symbol\n# ........  ........  ..................  .....................................\n#\n    42.35%  path_planner  libopencv_core.so   cv::Mat::copyTo(cv::Mat&) const\n    18.92%  path_planner  path_planner        AStar::findPath(Node, Node)\n    12.44%  path_planner  libc.so.6           __memcpy_avx_unaligned_erms\n     8.71%  path_planner  libstdc++.so.6      std::vector::_M_realloc_insert\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Diagnosis"}),": 42% of CPU time spent copying OpenCV matrices unnecessarily!"]}),"\n",(0,s.jsx)(n.h3,{id:"step-2-generate-flame-graph",children:"Step 2: Generate Flame Graph"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Convert perf data to flame graph\nsudo perf script | stackcollapse-perf.pl | flamegraph.pl > flamegraph.svg\n\n# Open in browser\nfirefox flamegraph.svg\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Flame Graph Interpretation"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Width"}),": Time spent in function (wider = slower)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Color"}),": Just for visibility (not meaningful)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Stacks"}),": Call hierarchy (bottom = main, top = leaf functions)"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://flamegraph.org/example-collapsed.svg",alt:"Flame graph example showing cv::Mat::copyTo dominating execution"})}),"\n",(0,s.jsx)(n.h3,{id:"step-3-fix-the-bottleneck",children:"Step 3: Fix the Bottleneck"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Before"})," (slow):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'void PathPlanner::processImage(const sensor_msgs::msg::Image& msg) {\n    cv::Mat input = cv_bridge::toCvCopy(msg, "bgr8")->image;  // COPY!\n    cv::Mat gray;\n    cv::cvtColor(input, gray, cv::COLOR_BGR2GRAY);  // COPY!\n    cv::Mat edges;\n    cv::Canny(gray, edges, 50, 150);  // COPY!\n}\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"After"})," (fast):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'void PathPlanner::processImage(const sensor_msgs::msg::Image& msg) {\n    // Use zero-copy bridge\n    cv_bridge::CvImageConstPtr input = cv_bridge::toCvShare(msg, "bgr8");\n\n    // Pre-allocate buffers (reuse across frames)\n    static cv::Mat gray, edges;\n\n    // In-place operations where possible\n    cv::cvtColor(input->image, gray, cv::COLOR_BGR2GRAY);\n    cv::Canny(gray, edges, 50, 150);\n}\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Results"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Before: 5 Hz, 42% CPU in ",(0,s.jsx)(n.code,{children:"copyTo()"})]}),"\n",(0,s.jsxs)(n.li,{children:["After: ",(0,s.jsx)(n.strong,{children:"22 Hz"}),", 8% CPU in ",(0,s.jsx)(n.code,{children:"copyTo()"})," \u2705"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"4.4x speedup"})," from eliminating unnecessary copies"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"hands-on-section-2-gpu-optimization-with-nvidia-nsight",children:"Hands-On Section 2: GPU Optimization with NVIDIA Nsight"}),"\n",(0,s.jsx)(n.h3,{id:"profiling-cuda-kernels",children:"Profiling CUDA Kernels"}),"\n",(0,s.jsx)(n.p,{children:"Let's optimize a custom CUDA kernel for image preprocessing (RGB \u2192 grayscale + normalization)."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Initial Implementation"})," (naive):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cuda",metastring:'title="preprocess.cu (slow)"',children:"__global__ void rgbToGrayNormalize(const uint8_t* rgb, float* gray,\n                                    int width, int height) {\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (x < width && y < height) {\n        int idx = y * width + x;\n\n        // Uncoalesced memory access (BAD!)\n        uint8_t r = rgb[idx * 3 + 0];\n        uint8_t g = rgb[idx * 3 + 1];\n        uint8_t b = rgb[idx * 3 + 2];\n\n        // Grayscale conversion\n        float gray_val = 0.299f * r + 0.587f * g + 0.114f * b;\n\n        // Normalize to [0, 1]\n        gray[idx] = gray_val / 255.0f;\n    }\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"profile-with-nsight-compute",children:"Profile with Nsight Compute"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Compile with debug symbols\nnvcc -O3 -lineinfo preprocess.cu -o preprocess\n\n# Profile kernel\nncu --set full --export profile ./preprocess\n\n# Open GUI\nncu-ui profile.ncu-rep\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Key Metrics"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Memory Throughput"}),": 45% of peak (POOR)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Compute Throughput"}),": 12% of peak (TERRIBLE)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Occupancy"}),": 28% (LOW)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Warp Execution Efficiency"}),": 62% (FAIR)"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Diagnosis"}),": Memory access pattern is strided (RGB interleaved), causing cache misses."]}),"\n",(0,s.jsx)(n.h3,{id:"optimized-implementation",children:"Optimized Implementation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cuda",metastring:'title="preprocess_optimized.cu (fast)"',children:"__global__ void rgbToGrayNormalizeOptimized(const uchar3* rgb, float* gray,\n                                             int width, int height) {\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (x < width && y < height) {\n        int idx = y * width + x;\n\n        // Coalesced access using uchar3 (128-bit loads)\n        uchar3 pixel = rgb[idx];\n\n        // Fused multiply-add (single instruction)\n        float gray_val = fmaf(0.299f, pixel.x,\n                         fmaf(0.587f, pixel.y, 0.114f * pixel.z));\n\n        gray[idx] = gray_val * 0.00392157f;  // 1/255 precomputed\n    }\n}\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Key Improvements"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Coalesced access"}),": ",(0,s.jsx)(n.code,{children:"uchar3"})," ensures consecutive threads access consecutive memory"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Vectorized loads"}),": 128-bit loads instead of 3\xd7 8-bit loads"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"FMA instructions"}),": Fused multiply-add reduces instruction count"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Constant folding"}),": ",(0,s.jsx)(n.code,{children:"1/255.0f"})," \u2192 ",(0,s.jsx)(n.code,{children:"0.00392157f"})," (compile-time constant)"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Results"}),":"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Metric"}),(0,s.jsx)(n.th,{children:"Before"}),(0,s.jsx)(n.th,{children:"After"}),(0,s.jsx)(n.th,{children:"Improvement"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Execution Time"})}),(0,s.jsx)(n.td,{children:"2.4 ms"}),(0,s.jsx)(n.td,{children:"0.38 ms"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"6.3x faster"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Memory Throughput"})}),(0,s.jsx)(n.td,{children:"45%"}),(0,s.jsx)(n.td,{children:"87%"}),(0,s.jsx)(n.td,{children:"1.9x better"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Occupancy"})}),(0,s.jsx)(n.td,{children:"28%"}),(0,s.jsx)(n.td,{children:"75%"}),(0,s.jsx)(n.td,{children:"2.7x better"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"FPS (1920x1080)"})}),(0,s.jsx)(n.td,{children:"416 FPS"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"2630 FPS"})}),(0,s.jsx)(n.td,{children:"6.3x"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"hands-on-section-3-ros-2-performance-tuning",children:"Hands-On Section 3: ROS 2 Performance Tuning"}),"\n",(0,s.jsx)(n.h3,{id:"qos-policy-optimization",children:"QoS Policy Optimization"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Default QoS"})," (reliable, keep-all) causes message queuing and latency spikes."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",metastring:'title="camera_publisher.py (before)"',children:"from rclpy.qos import QoSProfile\n\n# Default: reliable, keep-all history\npublisher = node.create_publisher(Image, '/camera/image', 10)\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Optimized QoS"})," for real-time camera streams:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",metastring:'title="camera_publisher_optimized.py (after)"',children:"from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy, DurabilityPolicy\n\n# Best-effort, keep-last-1 for minimal latency\ncamera_qos = QoSProfile(\n    reliability=ReliabilityPolicy.BEST_EFFORT,\n    history=HistoryPolicy.KEEP_LAST,\n    depth=1,\n    durability=DurabilityPolicy.VOLATILE\n)\n\npublisher = node.create_publisher(Image, '/camera/image', camera_qos)\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Benchmarks"})," (ROS 2 Humble, localhost):"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"QoS Config"}),(0,s.jsx)(n.th,{children:"Avg Latency"}),(0,s.jsx)(n.th,{children:"P95 Latency"}),(0,s.jsx)(n.th,{children:"Dropped Frames"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Reliable, depth=10"}),(0,s.jsx)(n.td,{children:"42 ms"}),(0,s.jsx)(n.td,{children:"180 ms"}),(0,s.jsx)(n.td,{children:"0%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Best-effort, depth=1"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"3.2 ms"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"8 ms"})}),(0,s.jsx)(n.td,{children:"0.02%"})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"When to use each"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Reliable"}),": Sensor calibration, map updates, critical commands"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Best-effort"}),": Camera streams, laser scans, odometry (high-rate data)"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"zero-copy-transport-intra-process-communication",children:"Zero-Copy Transport (Intra-Process Communication)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Traditional ROS 2"})," copies messages between nodes:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Publisher \u2192 Serialize \u2192 Middleware \u2192 Deserialize \u2192 Subscriber\n           (20-50 MB/s overhead for images)\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Zero-copy"})," shares pointers within the same process:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",metastring:'title="zero_copy_demo.py"',children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom rclpy.executors import SingleThreadedExecutor\n\nclass ImagePublisher(Node):\n    def __init__(self):\n        super().__init__('image_publisher')\n        self.pub = self.create_publisher(Image, '/camera/image', 10)\n        self.timer = self.create_timer(0.033, self.publish_image)\n\n    def publish_image(self):\n        msg = Image()\n        msg.height = 1080\n        msg.width = 1920\n        msg.encoding = 'rgb8'\n        msg.data = bytes(1920 * 1080 * 3)  # 6.2 MB\n        self.pub.publish(msg)\n\nclass ImageSubscriber(Node):\n    def __init__(self):\n        super().__init__('image_subscriber')\n        self.sub = self.create_subscription(Image, '/camera/image',\n                                             self.callback, 10)\n\n    def callback(self, msg):\n        # Process image (zero-copy if intra-process)\n        pass\n\ndef main():\n    rclpy.init()\n\n    # Single process enables zero-copy\n    pub_node = ImagePublisher()\n    sub_node = ImageSubscriber()\n\n    # Use MultiThreadedExecutor or SingleThreadedExecutor\n    executor = SingleThreadedExecutor()\n    executor.add_node(pub_node)\n    executor.add_node(sub_node)\n\n    executor.spin()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Benchmarks"})," (1920\xd71080 RGB, 30 FPS):"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Configuration"}),(0,s.jsx)(n.th,{children:"CPU Usage"}),(0,s.jsx)(n.th,{children:"Latency"}),(0,s.jsx)(n.th,{children:"Memory BW"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Inter-process (DDS)"}),(0,s.jsx)(n.td,{children:"38%"}),(0,s.jsx)(n.td,{children:"12 ms"}),(0,s.jsx)(n.td,{children:"560 MB/s"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Intra-process (zero-copy)"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"8%"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"0.4 ms"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"45 MB/s"})})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Speedup"}),": 30x reduction in memory bandwidth, 15x latency improvement \u2705"]}),"\n",(0,s.jsx)(n.h3,{id:"multi-threaded-executor-for-parallel-callbacks",children:"Multi-Threaded Executor for Parallel Callbacks"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Default executor"})," processes callbacks sequentially:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# SingleThreadedExecutor: callback1 \u2192 callback2 \u2192 callback3 (serial)\nexecutor = SingleThreadedExecutor()\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Multi-threaded executor"})," parallelizes independent callbacks:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",metastring:'title="multithreaded_executor_demo.py"',children:"from rclpy.executors import MultiThreadedExecutor\n\n# Run 4 callbacks in parallel\nexecutor = MultiThreadedExecutor(num_threads=4)\nexecutor.add_node(camera_node)\nexecutor.add_node(lidar_node)\nexecutor.add_node(imu_node)\nexecutor.add_node(planner_node)\n\nexecutor.spin()\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Benchmarks"})," (4 independent sensors @ 30 Hz):"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Executor"}),(0,s.jsx)(n.th,{children:"Total Latency"}),(0,s.jsx)(n.th,{children:"CPU Cores Used"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Single-threaded"}),(0,s.jsx)(n.td,{children:"120 ms"}),(0,s.jsx)(n.td,{children:"1"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Multi-threaded (4)"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"32 ms"})}),(0,s.jsx)(n.td,{children:"3.8"})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"\u26a0\ufe0f Caveats"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Thread-safety required (use locks for shared state)"}),"\n",(0,s.jsx)(n.li,{children:"Callback order is non-deterministic"}),"\n",(0,s.jsx)(n.li,{children:"Overhead: ~0.5 ms per callback context switch"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"advanced-topics-tensorrt-and-quantization",children:"Advanced Topics: TensorRT and Quantization"}),"\n",(0,s.jsx)(n.h3,{id:"tensorrt-optimization-pipeline",children:"TensorRT Optimization Pipeline"}),"\n",(0,s.jsx)(n.p,{children:"NVIDIA TensorRT optimizes neural networks for inference:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Layer fusion"}),": Conv + BatchNorm + ReLU \u2192 single kernel"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Precision calibration"}),": FP32 \u2192 FP16 \u2192 INT8"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Kernel auto-tuning"}),": Profile best CUDA kernels for your GPU"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Example"}),": Optimize YOLOv8 for Jetson Orin"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",metastring:'title="tensorrt_optimization.py"',children:"import tensorrt as trt\nimport torch\nfrom ultralytics import YOLO\n\n# Load PyTorch model\nmodel = YOLO('yolov8n.pt')\n\n# Export to ONNX\nmodel.export(format='onnx', simplify=True)\n\n# Build TensorRT engine with INT8 quantization\ndef build_engine(onnx_path, engine_path, precision='fp16'):\n    logger = trt.Logger(trt.Logger.WARNING)\n    builder = trt.Builder(logger)\n    network = builder.create_network(\n        1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n    )\n    parser = trt.OnnxParser(network, logger)\n\n    # Parse ONNX\n    with open(onnx_path, 'rb') as f:\n        parser.parse(f.read())\n\n    # Configure builder\n    config = builder.create_builder_config()\n    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 4 << 30)  # 4GB\n\n    # Set precision\n    if precision == 'fp16':\n        config.set_flag(trt.BuilderFlag.FP16)\n    elif precision == 'int8':\n        config.set_flag(trt.BuilderFlag.INT8)\n        # Requires calibration dataset for INT8\n        config.int8_calibrator = ImagenetCalibrator('calib_data/', batch_size=8)\n\n    # Build engine\n    engine = builder.build_serialized_network(network, config)\n\n    # Save\n    with open(engine_path, 'wb') as f:\n        f.write(engine)\n\n    return engine\n\n# Build engines\nbuild_engine('yolov8n.onnx', 'yolov8n_fp32.engine', 'fp32')\nbuild_engine('yolov8n.onnx', 'yolov8n_fp16.engine', 'fp16')\nbuild_engine('yolov8n.onnx', 'yolov8n_int8.engine', 'int8')\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Benchmarks"})," (Jetson Orin Nano, 1920\xd71080 input):"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Precision"}),(0,s.jsx)(n.th,{children:"Latency"}),(0,s.jsx)(n.th,{children:"FPS"}),(0,s.jsx)(n.th,{children:"mAP@0.5"}),(0,s.jsx)(n.th,{children:"Model Size"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"FP32"})}),(0,s.jsx)(n.td,{children:"45 ms"}),(0,s.jsx)(n.td,{children:"22"}),(0,s.jsx)(n.td,{children:"37.3%"}),(0,s.jsx)(n.td,{children:"25 MB"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"FP16"})}),(0,s.jsx)(n.td,{children:"22 ms"}),(0,s.jsx)(n.td,{children:"45"}),(0,s.jsx)(n.td,{children:"37.2%"}),(0,s.jsx)(n.td,{children:"13 MB"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"INT8"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"8.5 ms"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"118"})}),(0,s.jsx)(n.td,{children:"36.8%"}),(0,s.jsx)(n.td,{children:"6.5 MB"})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Key Takeaways"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"FP16"}),": Nearly free (0.1% accuracy loss), 2x speedup"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"INT8"}),": 5x speedup, 1.3% accuracy loss (acceptable for most tasks)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Batch size"}),": Increase for throughput (batch=4 \u2192 180 FPS), but 4x latency"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"quantization-aware-training-qat",children:"Quantization-Aware Training (QAT)"}),"\n",(0,s.jsx)(n.p,{children:"For minimal INT8 accuracy loss, train with quantization:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",metastring:'title="qat_training.py"',children:"import torch\nfrom torch.quantization import prepare_qat, convert\n\n# Prepare model for QAT\nmodel.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\nmodel_prepared = prepare_qat(model.train())\n\n# Train normally\nfor epoch in range(10):\n    for batch in dataloader:\n        loss = criterion(model_prepared(batch.images), batch.labels)\n        loss.backward()\n        optimizer.step()\n\n# Convert to quantized model\nmodel_quantized = convert(model_prepared.eval())\n\n# Export to ONNX \u2192 TensorRT INT8\ntorch.onnx.export(model_quantized, dummy_input, 'yolo_qat.onnx')\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Results"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Post-Training Quantization (PTQ): 37.3% \u2192 36.8% mAP (-1.3%)"}),"\n",(0,s.jsxs)(n.li,{children:["Quantization-Aware Training (QAT): 37.3% \u2192 ",(0,s.jsx)(n.strong,{children:"37.1% mAP (-0.5%)"})," \u2705"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"multi-gpu-scaling-for-4-camera-systems",children:"Multi-GPU Scaling for 4-Camera Systems"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Challenge"}),": Process 4\xd7 1920\xd71080 cameras at 60 FPS for 360\xb0 object detection."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Single-GPU bottleneck"}),": 4 \xd7 60 FPS = 240 inferences/sec"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["YOLOv8n @ INT8: 118 FPS max \u2192 ",(0,s.jsx)(n.strong,{children:"can't keep up"})]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solution"}),": Distribute cameras across 2 GPUs"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",metastring:'title="multi_gpu_inference.py"',children:"import torch\nimport torch.multiprocessing as mp\nfrom ultralytics import YOLO\n\ndef inference_worker(gpu_id, camera_ids, result_queue):\n    \"\"\"Run inference on assigned cameras\"\"\"\n    torch.cuda.set_device(gpu_id)\n    model = YOLO('yolov8n_int8.engine').to(f'cuda:{gpu_id}')\n\n    while True:\n        frames = get_frames(camera_ids)  # Fetch from cameras\n\n        # Batch inference\n        results = model(frames, stream=True)\n\n        for r in results:\n            result_queue.put(r.boxes.data)  # Send to main thread\n\ndef main():\n    # Spawn GPU processes\n    ctx = mp.get_context('spawn')\n    result_queue = ctx.Queue()\n\n    # GPU 0: cameras 0, 1\n    p0 = ctx.Process(target=inference_worker, args=(0, [0, 1], result_queue))\n    # GPU 1: cameras 2, 3\n    p1 = ctx.Process(target=inference_worker, args=(1, [2, 3], result_queue))\n\n    p0.start()\n    p1.start()\n\n    # Collect results\n    while True:\n        detections = result_queue.get()\n        # Fuse detections, publish to ROS 2\n        publish_detections(detections)\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Performance"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Single GPU: 118 FPS (can't handle 4\xd760=240)"}),"\n",(0,s.jsxs)(n.li,{children:["Dual GPU: ",(0,s.jsx)(n.strong,{children:"4\xd760 FPS = 240 FPS sustained"})," \u2705"]}),"\n",(0,s.jsx)(n.li,{children:"Latency: 8.5 ms (unchanged)"}),"\n",(0,s.jsx)(n.li,{children:"Power: 30W (2\xd7 Jetson Orin Nano)"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,s.jsx)(n.h3,{id:"easy-fundamentals",children:"Easy (Fundamentals)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Exercise 1"}),": Profile a simple ROS 2 node"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Task: Identify which function consumes most CPU time\nros2 run demo_nodes_cpp talker &\nsudo perf record -F 99 -p $! -g -- sleep 10\nsudo perf report\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Expected"}),": ",(0,s.jsx)(n.code,{children:"rcl_publish()"})," and ",(0,s.jsx)(n.code,{children:"rmw_publish()"})," dominate (70%+)"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Exercise 2"}),": Measure message latency"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Task: Compute round-trip latency for Image messages\n# Hint: Add timestamp in publisher, measure delta in subscriber\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Target"}),": <5ms for localhost, best-effort QoS"]}),"\n",(0,s.jsx)(n.h3,{id:"medium-real-world-optimization",children:"Medium (Real-World Optimization)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Exercise 3"}),": Optimize perception pipeline (2x speedup)"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Given"}),": ROS 2 node running at 15 FPS (CPU-bound)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Task"}),": Achieve 30 FPS using profiling + optimization"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Tools"}),": perf, flame graphs, zero-copy transport"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Success"}),": 2x FPS increase, <50% CPU usage"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Exercise 4"}),": TensorRT INT8 conversion"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Task"}),": Convert ResNet50 to TensorRT INT8, benchmark"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Target"}),": <10ms inference on RTX 3060, <1% accuracy loss"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Deliverable"}),": TensorRT engine + calibration script"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"hard-multi-gpu-production-system",children:"Hard (Multi-GPU Production System)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Exercise 5"}),": 4-camera, 60 FPS object detection"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Requirements"}),":","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"4\xd7 1920\xd71080 USB cameras"}),"\n",(0,s.jsx)(n.li,{children:"YOLOv8 inference on each stream"}),"\n",(0,s.jsxs)(n.li,{children:["Publish fused detections to ",(0,s.jsx)(n.code,{children:"/objects"})," topic"]}),"\n",(0,s.jsx)(n.li,{children:"Total latency <30ms (capture \u2192 detection \u2192 publish)"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Hardware"}),": 2\xd7 NVIDIA Jetson Orin Nano or 1\xd7 RTX 4080"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Success Criteria"}),":","\n",(0,s.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Sustained 60 FPS per camera (240 total inferences/sec)"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","<30ms end-to-end latency (p95)"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","GPU utilization 70-90% (not over-provisioned)"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","CPU usage <40% (offloaded to GPU)"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Hint"}),": Use pipeline parallelism:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Camera \u2192 Preprocessing (CPU) \u2192 Inference (GPU) \u2192 Postprocessing (CPU) \u2192 Publish\n         [Thread 1]            [CUDA Stream 0-3]  [Thread 2]\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"You've mastered the complete performance optimization toolkit for physical AI:"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Profiling"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\u2705 CPU flame graphs expose hidden bottlenecks (42% in ",(0,s.jsx)(n.code,{children:"cv::Mat::copyTo"}),")"]}),"\n",(0,s.jsx)(n.li,{children:"\u2705 NVIDIA Nsight identifies memory coalescing issues"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 ROS 2 tracing reveals QoS-induced latency spikes"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Optimization Techniques"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"\u2705 Zero-copy transport: 30x memory bandwidth reduction"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Multi-threaded executors: 4x throughput for parallel tasks"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 TensorRT INT8 quantization: 5x inference speedup, <2% accuracy loss"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Multi-GPU scaling: 4-camera, 60 FPS object detection"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Key Principles"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Measure first"}),": 80% of optimization time should be profiling"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Amdahl's Law"}),": Parallelism has diminishing returns; optimize serial code first"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Memory is king"}),": Bandwidth bottlenecks dominate robotics workloads"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Latency \u2260 Throughput"}),": Control requires low latency; perception needs high throughput"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Next Steps"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Explore ",(0,s.jsx)(n.strong,{children:"multi-threaded ROS 2 composition"})," for complex perception pipelines"]}),"\n",(0,s.jsxs)(n.li,{children:["Study ",(0,s.jsx)(n.strong,{children:"CUDA Graphs"})," for ultra-low-latency inference (<2ms)"]}),"\n",(0,s.jsxs)(n.li,{children:["Investigate ",(0,s.jsx)(n.strong,{children:"Jetson Power Modes"})," for battery-powered robots"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Real-World Impact"}),": These techniques enabled Tesla Optimus to achieve 200 Hz control loops, Boston Dynamics Spot to process 5 camera streams simultaneously, and Unitree H1 to perform dynamic backflips with <10ms visual feedback latency."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Academic Papers"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:['Nvidia TensorRT Team. "TensorRT: High-Performance Deep Learning Inference." ',(0,s.jsx)(n.em,{children:"arXiv:2011.12894"})," (2020)."]}),"\n",(0,s.jsxs)(n.li,{children:['Macenski et al. "Robot Operating System 2: Design, Architecture, and Uses in the Wild." ',(0,s.jsx)(n.em,{children:"Science Robotics"})," 7.66 (2022)."]}),"\n",(0,s.jsxs)(n.li,{children:["Patterson & Hennessy. ",(0,s.jsx)(n.em,{children:"Computer Architecture: A Quantitative Approach"}),", 6th ed. Ch. 1 (Amdahl's Law)."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Documentation"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://docs.nvidia.com/nsight-systems/",children:"NVIDIA Nsight Systems User Guide"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://docs.ros.org/en/humble/How-To-Guides/DDS-tuning.html",children:"ROS 2 Performance Best Practices"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/",children:"TensorRT Developer Guide"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsxs)(n.a,{href:"https://perf.wiki.kernel.org/index.php/Tutorial",children:["Linux ",(0,s.jsx)(n.code,{children:"perf"})," Tutorial"]})}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Tools"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/brendangregg/FlameGraph",children:"FlameGraph by Brendan Gregg"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/benfred/py-spy",children:"py-spy: Python Profiler"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://gitlab.com/ros-tracing/ros2_tracing",children:"ROS 2 Tracing Tools"})}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Hardware Specifications"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://developer.nvidia.com/embedded/jetson-benchmarks",children:"Jetson Orin Performance Benchmarks"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.scanofthetower.com/pcie-calculator/",children:"PCIe Bandwidth Calculator"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);