"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[9958],{8453:(e,n,a)=>{a.d(n,{R:()=>t,x:()=>c});var s=a(6540);const i={},r=s.createContext(i);function t(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),s.createElement(r.Provider,{value:n},e.children)}},8892:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>c,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"module3/isaac-ros","title":"Isaac ROS: GPU-Accelerated Perception","description":"Leverage NVIDIA Isaac ROS GEMs for hardware-accelerated VSLAM, object detection, and pose estimation","source":"@site/docs/module3/isaac-ros.md","sourceDirName":"module3","slug":"/module3/isaac-ros","permalink":"/hackathon-book/docs/module3/isaac-ros","draft":false,"unlisted":false,"editUrl":"https://github.com/MuhammadAhmed-Professional/hackathon-book/tree/master/frontend/docs/module3/isaac-ros.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"isaac-ros","title":"Isaac ROS: GPU-Accelerated Perception","sidebar_position":2,"description":"Leverage NVIDIA Isaac ROS GEMs for hardware-accelerated VSLAM, object detection, and pose estimation"},"sidebar":"tutorialSidebar","previous":{"title":"Isaac Sim","permalink":"/hackathon-book/docs/module3/isaac-sim"},"next":{"title":"Jetson Deployment","permalink":"/hackathon-book/docs/module3/jetson-deployment"}}');var i=a(4848),r=a(8453);const t={id:"isaac-ros",title:"Isaac ROS: GPU-Accelerated Perception",sidebar_position:2,description:"Leverage NVIDIA Isaac ROS GEMs for hardware-accelerated VSLAM, object detection, and pose estimation"},c="Isaac ROS: GPU-Accelerated Perception",l={},o=[{value:"What is Isaac ROS?",id:"what-is-isaac-ros",level:2},{value:"Isaac ROS GEMs (Pre-Built Modules)",id:"isaac-ros-gems-pre-built-modules",level:3},{value:"Architecture: CPU vs GPU Pipeline",id:"architecture-cpu-vs-gpu-pipeline",level:2},{value:"Traditional CPU Pipeline",id:"traditional-cpu-pipeline",level:3},{value:"Isaac ROS GPU Pipeline",id:"isaac-ros-gpu-pipeline",level:3},{value:"Installing Isaac ROS",id:"installing-isaac-ros",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Installation via apt (Recommended)",id:"installation-via-apt-recommended",level:3},{value:"Building from Source (Advanced)",id:"building-from-source-advanced",level:3},{value:"Isaac ROS Visual SLAM: Camera-Based Localization",id:"isaac-ros-visual-slam-camera-based-localization",level:2},{value:"Launch File Example",id:"launch-file-example",level:3},{value:"Calibration",id:"calibration",level:3},{value:"Isaac ROS AprilTag: Fiducial Markers",id:"isaac-ros-apriltag-fiducial-markers",level:2},{value:"Setup",id:"setup",level:3},{value:"Launch File",id:"launch-file",level:3},{value:"Isaac ROS DOPE: 3D Object Pose Estimation",id:"isaac-ros-dope-3d-object-pose-estimation",level:2},{value:"Training Custom Objects",id:"training-custom-objects",level:3},{value:"Inference",id:"inference",level:3},{value:"Integration with Nav2",id:"integration-with-nav2",level:2},{value:"Performance Benchmarks",id:"performance-benchmarks",level:2},{value:"When to Use Isaac ROS",id:"when-to-use-isaac-ros",level:2},{value:"Practical Exercise",id:"practical-exercise",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"isaac-ros-gpu-accelerated-perception",children:"Isaac ROS: GPU-Accelerated Perception"})}),"\n",(0,i.jsxs)(n.p,{children:["Perception\u2014the ability to understand the environment through sensors\u2014is the bottleneck in most robotic systems. Traditional CPU-based algorithms struggle to process 4K camera feeds at 30 FPS while simultaneously running SLAM, object detection, and depth estimation. ",(0,i.jsx)(n.strong,{children:"NVIDIA Isaac ROS"})," solves this by offloading compute-intensive perception tasks to the GPU, achieving 10-100x speedups on NVIDIA hardware."]}),"\n",(0,i.jsx)(n.p,{children:"In this chapter, you'll discover the Isaac ROS ecosystem, learn to deploy hardware-accelerated perception pipelines, integrate with ROS 2 Navigation, and understand when GPU acceleration provides the greatest value for humanoid robotics."}),"\n",(0,i.jsx)(n.h2,{id:"what-is-isaac-ros",children:"What is Isaac ROS?"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS"})," is a collection of GPU-accelerated ROS 2 packages (called ",(0,i.jsx)(n.strong,{children:"GEMs"}),") that replace standard CPU-based perception nodes with CUDA-optimized implementations. These packages leverage NVIDIA's deep learning, computer vision, and robotics expertise to deliver production-grade performance."]}),"\n",(0,i.jsx)(n.h3,{id:"isaac-ros-gems-pre-built-modules",children:"Isaac ROS GEMs (Pre-Built Modules)"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"GEM"}),(0,i.jsx)(n.th,{children:"Function"}),(0,i.jsx)(n.th,{children:"Typical Speedup"}),(0,i.jsx)(n.th,{children:"Hardware Requirement"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Visual SLAM"})}),(0,i.jsx)(n.td,{children:"Camera-based localization & mapping"}),(0,i.jsx)(n.td,{children:"5-10x"}),(0,i.jsx)(n.td,{children:"Jetson Orin / RTX GPU"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Depth Estimation"})}),(0,i.jsx)(n.td,{children:"Stereo depth from dual cameras"}),(0,i.jsx)(n.td,{children:"20-50x"}),(0,i.jsx)(n.td,{children:"Jetson Orin / RTX GPU"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Object Detection"})}),(0,i.jsx)(n.td,{children:"YOLO, DOPE (3D pose estimation)"}),(0,i.jsx)(n.td,{children:"30-100x"}),(0,i.jsx)(n.td,{children:"Jetson Orin / RTX GPU"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Image Segmentation"})}),(0,i.jsx)(n.td,{children:"U-Net, SegFormer for semantic segmentation"}),(0,i.jsx)(n.td,{children:"15-40x"}),(0,i.jsx)(n.td,{children:"Jetson Orin / RTX GPU"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"AprilTag Detection"})}),(0,i.jsx)(n.td,{children:"Fiducial marker detection for calibration"}),(0,i.jsx)(n.td,{children:"10-20x"}),(0,i.jsx)(n.td,{children:"Jetson Xavier+"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Pose Estimation"})}),(0,i.jsx)(n.td,{children:"6-DOF object pose (DOPE algorithm)"}),(0,i.jsx)(n.td,{children:"25-60x"}),(0,i.jsx)(n.td,{children:"Jetson Orin / RTX GPU"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Key insight"}),": Isaac ROS doesn't replace ROS 2\u2014it enhances it. You still use standard ROS 2 tools (RViz, Nav2, MoveIt), but the perception nodes run on the GPU."]}),"\n",(0,i.jsx)(n.h2,{id:"architecture-cpu-vs-gpu-pipeline",children:"Architecture: CPU vs GPU Pipeline"}),"\n",(0,i.jsx)(n.h3,{id:"traditional-cpu-pipeline",children:"Traditional CPU Pipeline"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Camera \u2192 sensor_msgs/Image \u2192 CPU Node (OpenCV) \u2192 Processed Image \u2192 Nav2\n         30 FPS             ~100-200ms latency       15-20 FPS output\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": High-resolution images (1920x1080) overwhelm the CPU, causing dropped frames and high latency."]}),"\n",(0,i.jsx)(n.h3,{id:"isaac-ros-gpu-pipeline",children:"Isaac ROS GPU Pipeline"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Camera \u2192 sensor_msgs/Image \u2192 Isaac ROS Node (CUDA) \u2192 Processed Image \u2192 Nav2\n         30 FPS              ~5-15ms latency         30 FPS output\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Benefit"}),": GPU processes images 10x faster, maintaining real-time performance with no frame drops."]}),"\n",(0,i.jsx)(n.h2,{id:"installing-isaac-ros",children:"Installing Isaac ROS"}),"\n",(0,i.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Hardware"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["NVIDIA Jetson Orin Nano (8GB minimum) ",(0,i.jsx)(n.strong,{children:"or"})]}),"\n",(0,i.jsx)(n.li,{children:"Desktop with RTX 2060+ GPU"}),"\n",(0,i.jsx)(n.li,{children:"x86_64 or ARM64 architecture"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Software"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Ubuntu 20.04 or 22.04"}),"\n",(0,i.jsx)(n.li,{children:"ROS 2 Humble"}),"\n",(0,i.jsx)(n.li,{children:"NVIDIA JetPack 5.1+ (for Jetson) or CUDA 11.8+ (for desktop)"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"installation-via-apt-recommended",children:"Installation via apt (Recommended)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Add NVIDIA Isaac ROS apt repository\nsudo apt-get install -y software-properties-common\nsudo add-apt-repository ppa:nvidia-isaac-ros/ppa\nsudo apt-get update\n\n# Install Isaac ROS packages\nsudo apt-get install -y \\\n    ros-humble-isaac-ros-visual-slam \\\n    ros-humble-isaac-ros-apriltag \\\n    ros-humble-isaac-ros-depth-segmentation \\\n    ros-humble-isaac-ros-object-detection\n\n# Install dependencies\nsudo apt-get install -y \\\n    ros-humble-image-transport \\\n    ros-humble-image-transport-plugins \\\n    ros-humble-camera-calibration-parsers\n"})}),"\n",(0,i.jsx)(n.h3,{id:"building-from-source-advanced",children:"Building from Source (Advanced)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Create workspace\nmkdir -p ~/isaac_ros_ws/src\ncd ~/isaac_ros_ws/src\n\n# Clone Isaac ROS packages\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_common.git\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_visual_slam.git\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_apriltag.git\n\n# Build\ncd ~/isaac_ros_ws\ncolcon build --symlink-install\n\n# Source\nsource install/setup.bash\n"})}),"\n",(0,i.jsx)(n.h2,{id:"isaac-ros-visual-slam-camera-based-localization",children:"Isaac ROS Visual SLAM: Camera-Based Localization"}),"\n",(0,i.jsx)(n.p,{children:"Visual SLAM (vSLAM) enables robots to build maps and localize using only cameras\u2014no LIDAR required. Isaac ROS Visual SLAM implements a GPU-accelerated ORB-SLAM variant."}),"\n",(0,i.jsx)(n.h3,{id:"launch-file-example",children:"Launch File Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# launch/isaac_vslam.launch.py\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        # Camera node (e.g., RealSense D435i)\n        Node(\n            package='realsense2_camera',\n            executable='realsense2_camera_node',\n            name='camera',\n            parameters=[{\n                'enable_infra1': True,\n                'enable_infra2': True,\n                'enable_depth': False,  # vSLAM uses stereo infrared\n                'infra_width': 640,\n                'infra_height': 480,\n                'infra_fps': 30\n            }]\n        ),\n\n        # Isaac Visual SLAM node\n        Node(\n            package='isaac_ros_visual_slam',\n            executable='isaac_ros_visual_slam',\n            name='isaac_ros_visual_slam',\n            parameters=[{\n                'enable_rectified_pose': True,\n                'denoise_input_images': True,\n                'rectified_images': True,\n                'enable_debug_mode': False,\n                'debug_dump_path': '/tmp/isaac_vslam',\n                'map_frame': 'map',\n                'odom_frame': 'odom',\n                'base_frame': 'base_link',\n                'input_left_camera_frame': 'camera_infra1_frame',\n                'input_right_camera_frame': 'camera_infra2_frame'\n            }],\n            remappings=[\n                ('/stereo_camera/left/image', '/camera/infra1/image_rect_raw'),\n                ('/stereo_camera/left/camera_info', '/camera/infra1/camera_info'),\n                ('/stereo_camera/right/image', '/camera/infra2/image_rect_raw'),\n                ('/stereo_camera/right/camera_info', '/camera/infra2/camera_info')\n            ]\n        ),\n\n        # Visualize in RViz\n        Node(\n            package='rviz2',\n            executable='rviz2',\n            name='rviz2',\n            arguments=['-d', '$(find isaac_ros_visual_slam)/rviz/default.rviz']\n        )\n    ])\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Run"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch my_robot_bringup isaac_vslam.launch.py\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Output Topics"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/visual_slam/tracking/odometry"})," (nav_msgs/Odometry): Robot pose estimate"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/visual_slam/tracking/vo_pose"})," (geometry_msgs/PoseStamped): Visual odometry"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/visual_slam/vis/observations_cloud"})," (sensor_msgs/PointCloud2): Feature points"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/visual_slam/status"})," (isaac_ros_visual_slam_interfaces/VisualSlamStatus): System health"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Performance"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"CPU (ORB-SLAM3)"}),": ~15 FPS at 640x480, 150ms latency"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"GPU (Isaac ROS vSLAM)"}),": 30 FPS at 640x480, 15ms latency"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"calibration",children:"Calibration"}),"\n",(0,i.jsx)(n.p,{children:"vSLAM requires accurate camera calibration:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Calibrate stereo camera\nros2 run camera_calibration cameracalibrator \\\n    --size 8x6 \\\n    --square 0.025 \\\n    --no-service-check \\\n    --approximate 0.1 \\\n    left:=/camera/infra1/image_raw \\\n    right:=/camera/infra2/image_raw \\\n    left_camera:=/camera/infra1 \\\n    right_camera:=/camera/infra2\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Save calibration"})," to ",(0,i.jsx)(n.code,{children:"~/.ros/camera_info/"})," and configure camera node to load it."]}),"\n",(0,i.jsx)(n.h2,{id:"isaac-ros-apriltag-fiducial-markers",children:"Isaac ROS AprilTag: Fiducial Markers"}),"\n",(0,i.jsx)(n.p,{children:"AprilTags are 2D barcodes used for precise localization and object pose estimation."}),"\n",(0,i.jsx)(n.h3,{id:"setup",children:"Setup"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Install AprilTag GEM\nsudo apt-get install ros-humble-isaac-ros-apriltag\n"})}),"\n",(0,i.jsx)(n.h3,{id:"launch-file",children:"Launch File"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# launch/apriltag_detection.launch.py\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        # Camera\n        Node(\n            package='v4l2_camera',\n            executable='v4l2_camera_node',\n            name='camera',\n            parameters=[{\n                'image_size': [640, 480],\n                'camera_frame_id': 'camera_optical_frame'\n            }]\n        ),\n\n        # Isaac AprilTag detector\n        Node(\n            package='isaac_ros_apriltag',\n            executable='isaac_ros_apriltag',\n            name='apriltag',\n            parameters=[{\n                'family': '36h11',  # or '25h9', '16h5'\n                'size': 0.162,  # Tag size in meters (e.g., 162mm)\n                'max_tags': 20\n            }],\n            remappings=[\n                ('/image', '/camera/image_raw'),\n                ('/camera_info', '/camera/camera_info')\n            ]\n        )\n    ])\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Run"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch my_robot_bringup apriltag_detection.launch.py\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Subscribe to detections"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom isaac_ros_apriltag_interfaces.msg import AprilTagDetectionArray\n\nclass AprilTagListener(Node):\n    def __init__(self):\n        super().__init__('apriltag_listener')\n        self.subscription = self.create_subscription(\n            AprilTagDetectionArray,\n            '/tag_detections',\n            self.detection_callback,\n            10\n        )\n\n    def detection_callback(self, msg):\n        for detection in msg.detections:\n            tag_id = detection.id\n            pose = detection.pose.pose.pose\n\n            self.get_logger().info(\n                f'Tag {tag_id}: x={pose.position.x:.2f}, '\n                f'y={pose.position.y:.2f}, z={pose.position.z:.2f}'\n            )\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = AprilTagListener()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Use cases"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Docking"}),": AprilTag on charging station for precise alignment"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Object manipulation"}),": Tags on objects for 6-DOF pose estimation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Warehouse navigation"}),": Tags at shelf locations for localization"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"isaac-ros-dope-3d-object-pose-estimation",children:"Isaac ROS DOPE: 3D Object Pose Estimation"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"DOPE (Deep Object Pose Estimation)"})," infers 6-DOF pose (translation + rotation) from RGB images."]}),"\n",(0,i.jsx)(n.h3,{id:"training-custom-objects",children:"Training Custom Objects"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# 1. Generate synthetic training data (Isaac Sim)\n# - Place 3D model in random poses\n# - Render 50,000 images with annotations\n\n# 2. Train DOPE model\ngit clone https://github.com/NVlabs/Deep_Object_Pose.git\ncd Deep_Object_Pose\npython scripts/train.py --data /path/to/synthetic_data --epochs 100\n\n# 3. Export to ONNX for Isaac ROS\npython scripts/export_onnx.py --checkpoint model_epoch_100.pth\n"})}),"\n",(0,i.jsx)(n.h3,{id:"inference",children:"Inference"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# launch/dope_inference.launch.py\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='isaac_ros_dope',\n            executable='isaac_ros_dope',\n            name='dope',\n            parameters=[{\n                'model_file_path': '/path/to/model.onnx',\n                'object_name': 'coffee_mug',\n                'confidence_threshold': 0.5\n            }],\n            remappings=[\n                ('/image', '/camera/color/image_raw'),\n                ('/camera_info', '/camera/color/camera_info')\n            ]\n        )\n    ])\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Output"}),": ",(0,i.jsx)(n.code,{children:"geometry_msgs/PoseArray"})," with detected object poses."]}),"\n",(0,i.jsx)(n.h2,{id:"integration-with-nav2",children:"Integration with Nav2"}),"\n",(0,i.jsx)(n.p,{children:"Isaac ROS seamlessly integrates with Nav2 for autonomous navigation:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# launch/navigation_with_vslam.launch.py\nfrom launch import LaunchDescription\nfrom launch.actions import IncludeLaunchDescription\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch_ros.substitutions import FindPackageShare\n\ndef generate_launch_description():\n    return LaunchDescription([\n        # Isaac Visual SLAM (provides /odom \u2192 /base_link transform)\n        IncludeLaunchDescription(\n            PythonLaunchDescriptionSource([\n                FindPackageShare('my_robot_bringup'),\n                '/launch/isaac_vslam.launch.py'\n            ])\n        ),\n\n        # Nav2 (uses vSLAM odometry for localization)\n        IncludeLaunchDescription(\n            PythonLaunchDescriptionSource([\n                FindPackageShare('nav2_bringup'),\n                '/launch/navigation_launch.py'\n            ]),\n            launch_arguments={\n                'use_sim_time': 'false',\n                'params_file': '/path/to/nav2_params.yaml'\n            }.items()\n        )\n    ])\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Nav2 params"})," (",(0,i.jsx)(n.code,{children:"nav2_params.yaml"}),"):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'bt_navigator:\n  ros__parameters:\n    use_sim_time: false\n\ncontroller_server:\n  ros__parameters:\n    controller_frequency: 20.0\n    FollowPath:\n      plugin: "dwb_core::DWBLocalPlanner"\n      max_vel_x: 0.5\n      max_vel_theta: 1.0\n\nplanner_server:\n  ros__parameters:\n    planner_plugins: ["GridBased"]\n    GridBased:\n      plugin: "nav2_navfn_planner/NavfnPlanner"\n\n# Use Isaac vSLAM odometry\nlocal_costmap:\n  ros__parameters:\n    global_frame: odom\n    robot_base_frame: base_link\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Result"}),": Robot navigates using GPU-accelerated visual odometry from Isaac ROS."]}),"\n",(0,i.jsx)(n.h2,{id:"performance-benchmarks",children:"Performance Benchmarks"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Hardware"}),": Jetson Orin Nano 8GB vs Intel i7-10700K CPU"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Task"}),(0,i.jsx)(n.th,{children:"CPU (OpenCV)"}),(0,i.jsx)(n.th,{children:"GPU (Isaac ROS)"}),(0,i.jsx)(n.th,{children:"Speedup"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.strong,{children:"Visual SLAM"})," (640x480)"]}),(0,i.jsx)(n.td,{children:"15 FPS, 150ms"}),(0,i.jsx)(n.td,{children:"30 FPS, 15ms"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"10x"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.strong,{children:"AprilTag Detection"})," (640x480, 10 tags)"]}),(0,i.jsx)(n.td,{children:"10 FPS"}),(0,i.jsx)(n.td,{children:"30 FPS"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"3x"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.strong,{children:"DOPE Pose Estimation"})," (1920x1080)"]}),(0,i.jsx)(n.td,{children:"5 FPS"}),(0,i.jsx)(n.td,{children:"30 FPS"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"6x"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.strong,{children:"Stereo Depth"})," (1280x720)"]}),(0,i.jsx)(n.td,{children:"8 FPS"}),(0,i.jsx)(n.td,{children:"60 FPS"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"7.5x"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.strong,{children:"Object Detection (YOLOv8)"})," (1920x1080)"]}),(0,i.jsx)(n.td,{children:"4 FPS"}),(0,i.jsx)(n.td,{children:"120 FPS"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"30x"})})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Power consumption"}),": Jetson Orin Nano: 7-15W vs Desktop CPU: 65W+"]}),"\n",(0,i.jsx)(n.h2,{id:"when-to-use-isaac-ros",children:"When to Use Isaac ROS"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"\u2705 Use Isaac ROS when:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Running on NVIDIA Jetson (Orin, Xavier) or desktop RTX GPU"}),"\n",(0,i.jsx)(n.li,{children:"Processing high-resolution images (1080p+) in real-time"}),"\n",(0,i.jsx)(n.li,{children:"Deploying multiple perception algorithms simultaneously"}),"\n",(0,i.jsx)(n.li,{children:"Power-constrained scenarios (Jetson: 7-15W vs CPU: 65W+)"}),"\n",(0,i.jsx)(n.li,{children:"Need production-grade performance (30-120 FPS)"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"\u274c Don't use Isaac ROS when:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Running on non-NVIDIA hardware (Intel, AMD)"}),"\n",(0,i.jsx)(n.li,{children:"Prototyping with low-resolution images (< 640x480)"}),"\n",(0,i.jsx)(n.li,{children:"Perception is not the bottleneck"}),"\n",(0,i.jsx)(n.li,{children:"Deploying on resource-rich servers (cloud computing)"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"practical-exercise",children:"Practical Exercise"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Challenge"}),": Build a navigation system using Isaac ROS Visual SLAM:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Set up stereo camera (RealSense D435i or similar)"}),"\n",(0,i.jsx)(n.li,{children:"Launch Isaac ROS Visual SLAM node"}),"\n",(0,i.jsx)(n.li,{children:"Integrate with Nav2 for autonomous navigation"}),"\n",(0,i.jsx)(n.li,{children:"Send navigation goals via RViz2"}),"\n",(0,i.jsxs)(n.li,{children:["Measure:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"vSLAM update rate (should be \u2265 20 Hz)"}),"\n",(0,i.jsx)(n.li,{children:"Localization drift (< 1% of distance traveled)"}),"\n",(0,i.jsx)(n.li,{children:"CPU usage (should be < 50% with GPU offload)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Success criteria"}),":"]}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","vSLAM publishes odometry at \u2265 20 Hz"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Nav2 successfully reaches 5 navigation goals"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Localization error < 10 cm after 20m travel"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","CPU usage < 50%, GPU usage 60-80%"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,i.jsxs)(n.p,{children:["\u2705 ",(0,i.jsx)(n.strong,{children:"Isaac ROS GEMs"}),": Pre-built GPU-accelerated perception modules\n\u2705 ",(0,i.jsx)(n.strong,{children:"10-100x speedup"}),": GPU processing vs traditional CPU pipelines\n\u2705 ",(0,i.jsx)(n.strong,{children:"Visual SLAM"}),": Camera-only localization at 30 FPS\n\u2705 ",(0,i.jsx)(n.strong,{children:"AprilTag"}),": Fiducial marker detection for precise localization\n\u2705 ",(0,i.jsx)(n.strong,{children:"DOPE"}),": 6-DOF object pose estimation from RGB images\n\u2705 ",(0,i.jsx)(n.strong,{children:"Nav2 integration"}),": Seamless replacement for CPU-based perception\n\u2705 ",(0,i.jsx)(n.strong,{children:"Hardware"}),": Requires NVIDIA Jetson Orin or RTX GPU"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Next steps"}),": Learn about VSLAM algorithms in detail to understand how feature tracking, loop closure, and map optimization work under the hood."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Related chapters"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/hackathon-book/docs/module3/isaac-sim",children:"Isaac Sim"})," - Generate synthetic training data for DOPE"]}),"\n",(0,i.jsx)(n.li,{children:"VSLAM Navigation - Next chapter: deep dive into visual SLAM (coming soon)"}),"\n",(0,i.jsx)(n.li,{children:"Nav2 Planning - Integrate perception with path planning (coming soon)"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);